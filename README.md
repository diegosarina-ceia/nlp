<div align="center">

# Procesamiento del Lenguaje Natural

![UBA](image.png)

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![Deep Learning](https://img.shields.io/badge/Deep_Learning-2024-purple)
![NLP](https://img.shields.io/badge/NLP-Advanced-green)
</div>



## ğŸ¯ DescripciÃ³n General

Bienvenido al repositorio de resoluciones para la materia de Procesamiento del Lenguaje Natural del LSE-FIUBA. 

Este repositorio contiene los diferentes entregables que se desarrollaron como parte de **DesafÃ­os** de la asignatura NLP perteneciente a la EspecializaciÃ³n en IA de la UBA (Universidad Nacional de Buenos Aires).

## ğŸ“š DesafÃ­os Implementados

### 1ï¸âƒ£ DesafÃ­o NÂº 1: VectorizaciÃ³n de texto
En este desafÃ­o, se implementa el algoritmo Word2Vec para aprender representaciones vectoriales densas de palabras a partir de grandes corpus de texto. Estas representaciones permiten capturar similitudes semÃ¡nticas y relaciones entre palabras dentro de un espacio vectorial, facilitando el anÃ¡lisis de conexiones y patrones entre tÃ©rminos.

ğŸ“‚ [Ver implementaciÃ³n](DESAFIO_1/Desafio_1.ipynb)

### 2ï¸âƒ£ DesafÃ­o NÂº 2: Custom Embeddings con Gensim
En este desafÃ­o, se utiliza la biblioteca Gensim para generar embeddings de palabras a partir de un corpus de texto. Se exploran tÃ©cnicas como Skip-Gram y CBOW, aplicando los embeddings a tareas como bÃºsqueda de palabras similares, anÃ¡lisis de analogÃ­as, y otras tareas de procesamiento del lenguaje natural.

ğŸ“‚ [Ver implementaciÃ³n](DESAFIO_2/Desafio_2.ipynb)

### 3ï¸âƒ£ DesafÃ­o NÂº 3: Modelo de lenguaje con tokenizaciÃ³n
ImplementaciÃ³n dual de modelos de lenguaje:
- **Enfoque por palabras**: [Ver notebook](Desafio3/Desafio_3_word.ipynb)
- **Enfoque por caracteres**: [Ver notebook](Desafio3/Desafio_3_char.ipynb)

CaracterÃ­sticas principales:
- Arquitecturas RNN, LSTM y GRU
- ExperimentaciÃ³n con beam search y temperature sampling
- AnÃ¡lisis comparativo de estrategias de tokenizaciÃ³n

ğŸ“‚ [Ver implementaciÃ³n](DESAFIO_3/)

### 4ï¸âƒ£ DesafÃ­o NÂº 4: LSTM Bot QA
En este desafÃ­o, se desarrolla un bot de preguntas y respuestas (QA) utilizando un modelo encoder-decoder basado en LSTM. El bot es capaz de generar respuestas coherentes a preguntas simples en inglÃ©s. Para mejorar la representaciÃ³n semÃ¡ntica de las palabras, se utilizan embeddings de FastText. A lo largo del entrenamiento, se emplean tÃ©cnicas de regularizaciÃ³n como dropout para mitigar el sobreajuste, logrando un buen equilibrio entre calidad de las respuestas y generalizaciÃ³n del modelo.

ğŸ“‚ [Ver implementaciÃ³n](DESAFIO_4/DESAFIO_4.ipynb)

### 5ï¸âƒ£ DesafÃ­o NÂº 5: AnÃ¡lisis de Sentimientos con BERT
Este desafÃ­o explora el poder del anÃ¡lisis de sentimiento utilizando BERT para procesar y comprender reseÃ±as de aplicaciones. El proyecto se divide en dos aproximaciones principales:

- Modelo Base: ImplementaciÃ³n clÃ¡sica de clasificaciÃ³n tripartita (positivo/negativo/neutral) aprovechando la capacidad de BERT para entender el contexto bidireccional del texto.
- Modelo Extendido: Refinamiento que preserva las 5 categorÃ­as originales del dataset, permitiendo una granularidad mÃ¡s fina en la detecciÃ³n de sentimientos.

La arquitectura transformer de BERT, combinada con fine-tuning especÃ­fico para nuestro dominio, permite capturar sutilezas lingÃ¼Ã­sticas y contextuales que son cruciales para entender el verdadero sentimiento detrÃ¡s de cada reseÃ±a.

ğŸ“‚ [Ver implementaciÃ³n](DESAFIO_5/DESAFIO_5.ipynb)

## ğŸ“ Notas
- Todas las notebooks fueron desarrolladas y probadas en Google Colab
- Se recomienda revisar cada notebook para requisitos especÃ­ficos

---
<div align="center">
<i>Facultad de IngenierÃ­a - Universidad de Buenos Aires</i>
</div>