{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yeJGnCYxuF"
      },
      "source": [
        "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
        "\n",
        "\n",
        "# Procesamiento de lenguaje natural\n",
        "## Modelo de lenguaje con tokenización por caracteres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv5PEwGzZA9-"
      },
      "source": [
        "### Consigna\n",
        "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
        "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
        "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
        "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
        "\n",
        "\n",
        "### Sugerencias\n",
        "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
        "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
        "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Y-QdFbHZYj7C"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import io\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64sSgAvYt9sr",
        "outputId": "910a842b-2acf-4b58-a6fb-45345d06f77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n",
            "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
            "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Verifica si TensorFlow está utilizando GPU\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Verifica los dispositivos disponibles y sus detalles\n",
        "for device in tf.config.list_physical_devices():\n",
        "    print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTvXlEKQZdqx"
      },
      "source": [
        "### Datos\n",
        "\n",
        "Utilizo el libro **Harry Potter y La piedra filosofal**, de la autora J.K. Rowling para entrenar el modelo, de manera tal que la predicción de la palabra va a estar relacionada con el contexto de la historia dada en el libro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeUsG18VlGSr",
        "outputId": "f36abe57-3e91-488d-ef1a-fc652634fc5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "MSo_076Sl3g0"
      },
      "outputs": [],
      "source": [
        "# Path donde va a estar el libro en Colab\n",
        "\n",
        "filepath = r\"drive/MyDrive/Colab Notebooks/Book1.txt\"\n",
        "#filepath = 'Book1.txt' #local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4Fnuzn9gt9sr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# leo el archivo local\n",
        "with open(filepath, 'r', encoding='utf-8') as file:\n",
        "    article_text = file.read()\n",
        "\n",
        "# paso todo el texto a minúsculas\n",
        "article_text = article_text.lower()\n",
        "\n",
        "# elimino caracteres especiales y números, manteniendo solo texto y espacios\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)\n",
        "article_text = article_text.replace('/', '')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILXwRACCt9sr",
        "outputId": "05d2e2f9-aad3-4e7a-9de8-5fd638a20dcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " the boy who lived mr. and mrs. dursley, of number four, privet drive, were proud to say that they were perfectly normal, thank you very much. they were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense. mr. dursley was the director of a firm called grunnings, which made drills. he was a big, beefy man with hardly any neck, although he did have a very large mustache. mrs. dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. the dursley s had a small son called dudley and in their opinion there was no finer boy anywhere. the dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. they didn’t think they could bear it if anyone found out about the potters. mrs. potter was mrs. dursley’s sister, but they hadn’t p\n"
          ]
        }
      ],
      "source": [
        "# en article text se encuentra el texto de todo el libro\n",
        "print(article_text[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP1JdiOIKQWi"
      },
      "source": [
        "### Elegir el tamaño del contexto\n",
        "\n",
        "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
        "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
        "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wumBNwdjJM3j"
      },
      "outputs": [],
      "source": [
        "# seleccionamos el tamaño de contexto\n",
        "max_context_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "m5FeTaGvbDbw"
      },
      "outputs": [],
      "source": [
        "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
        "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "573Cg5n7VhWw"
      },
      "outputs": [],
      "source": [
        "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
        "chars_vocab = set(article_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTK6xgLJd8q",
        "outputId": "089be638-75f3-4ed5-d41a-d4cf23228b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La longitud de vocabulario de caracteres es: 57\n"
          ]
        }
      ],
      "source": [
        "# la longitud de vocabulario de caracteres es:\n",
        "print(f\"La longitud de vocabulario de caracteres es: {len(chars_vocab)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2W0AeQjXV1Ou"
      },
      "outputs": [],
      "source": [
        "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
        "# El diccionario `char2idx` servirá como tokenizador.\n",
        "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
        "idx2char = {v: k for k,v in char2idx.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oIUjVU0LB0r"
      },
      "source": [
        "###  Tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "h07G3srdJppo"
      },
      "outputs": [],
      "source": [
        "# tokenizamos el texto completo\n",
        "tokenized_text = [char2idx[ch] for ch in article_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwGVSKOiJ5bj",
        "outputId": "eb83a319-0eed-4d8c-b5a7-408225233134"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 7,\n",
              " 39,\n",
              " 33,\n",
              " 54,\n",
              " 9,\n",
              " 4,\n",
              " 39,\n",
              " 54,\n",
              " 1,\n",
              " 26,\n",
              " 31,\n",
              " 27,\n",
              " 43,\n",
              " 54,\n",
              " 19,\n",
              " 28,\n",
              " 53,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 43,\n",
              " 54,\n",
              " 19,\n",
              " 28,\n",
              " 24,\n",
              " 53,\n",
              " 54,\n",
              " 43,\n",
              " 23,\n",
              " 28,\n",
              " 24,\n",
              " 1,\n",
              " 27,\n",
              " 33,\n",
              " 41,\n",
              " 54,\n",
              " 39,\n",
              " 52,\n",
              " 54,\n",
              " 10,\n",
              " 23,\n",
              " 19,\n",
              " 7,\n",
              " 27,\n",
              " 28,\n",
              " 54,\n",
              " 52,\n",
              " 39,\n",
              " 23,\n",
              " 28,\n",
              " 41,\n",
              " 54,\n",
              " 20,\n",
              " 28,\n",
              " 26,\n",
              " 31,\n",
              " 27,\n",
              " 12,\n",
              " 54,\n",
              " 43,\n",
              " 28,\n",
              " 26,\n",
              " 31,\n",
              " 27,\n",
              " 41,\n",
              " 54,\n",
              " 9,\n",
              " 27,\n",
              " 28,\n",
              " 27,\n",
              " 54,\n",
              " 20,\n",
              " 28,\n",
              " 39,\n",
              " 23,\n",
              " 43,\n",
              " 54,\n",
              " 12,\n",
              " 39,\n",
              " 54,\n",
              " 24,\n",
              " 0,\n",
              " 33,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 0,\n",
              " 12,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 9,\n",
              " 27,\n",
              " 28,\n",
              " 27,\n",
              " 54,\n",
              " 20,\n",
              " 27,\n",
              " 28,\n",
              " 52,\n",
              " 27,\n",
              " 50,\n",
              " 12,\n",
              " 1,\n",
              " 33,\n",
              " 54,\n",
              " 10,\n",
              " 39,\n",
              " 28,\n",
              " 19,\n",
              " 0,\n",
              " 1,\n",
              " 41,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 0,\n",
              " 10,\n",
              " 55,\n",
              " 54,\n",
              " 33,\n",
              " 39,\n",
              " 23,\n",
              " 54,\n",
              " 31,\n",
              " 27,\n",
              " 28,\n",
              " 33,\n",
              " 54,\n",
              " 19,\n",
              " 23,\n",
              " 50,\n",
              " 4,\n",
              " 53,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 9,\n",
              " 27,\n",
              " 28,\n",
              " 27,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 1,\n",
              " 0,\n",
              " 24,\n",
              " 12,\n",
              " 54,\n",
              " 20,\n",
              " 27,\n",
              " 39,\n",
              " 20,\n",
              " 1,\n",
              " 27,\n",
              " 54,\n",
              " 33,\n",
              " 39,\n",
              " 23,\n",
              " 6,\n",
              " 43,\n",
              " 54,\n",
              " 27,\n",
              " 56,\n",
              " 20,\n",
              " 27,\n",
              " 50,\n",
              " 12,\n",
              " 54,\n",
              " 12,\n",
              " 39,\n",
              " 54,\n",
              " 7,\n",
              " 27,\n",
              " 54,\n",
              " 26,\n",
              " 10,\n",
              " 31,\n",
              " 39,\n",
              " 1,\n",
              " 31,\n",
              " 27,\n",
              " 43,\n",
              " 54,\n",
              " 26,\n",
              " 10,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 33,\n",
              " 12,\n",
              " 4,\n",
              " 26,\n",
              " 10,\n",
              " 21,\n",
              " 54,\n",
              " 24,\n",
              " 12,\n",
              " 28,\n",
              " 0,\n",
              " 10,\n",
              " 21,\n",
              " 27,\n",
              " 54,\n",
              " 39,\n",
              " 28,\n",
              " 54,\n",
              " 19,\n",
              " 33,\n",
              " 24,\n",
              " 12,\n",
              " 27,\n",
              " 28,\n",
              " 26,\n",
              " 39,\n",
              " 23,\n",
              " 24,\n",
              " 41,\n",
              " 54,\n",
              " 7,\n",
              " 27,\n",
              " 50,\n",
              " 0,\n",
              " 23,\n",
              " 24,\n",
              " 27,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 38,\n",
              " 23,\n",
              " 24,\n",
              " 12,\n",
              " 54,\n",
              " 43,\n",
              " 26,\n",
              " 43,\n",
              " 10,\n",
              " 6,\n",
              " 12,\n",
              " 54,\n",
              " 4,\n",
              " 39,\n",
              " 1,\n",
              " 43,\n",
              " 54,\n",
              " 9,\n",
              " 26,\n",
              " 12,\n",
              " 4,\n",
              " 54,\n",
              " 24,\n",
              " 23,\n",
              " 50,\n",
              " 4,\n",
              " 54,\n",
              " 10,\n",
              " 39,\n",
              " 10,\n",
              " 24,\n",
              " 27,\n",
              " 10,\n",
              " 24,\n",
              " 27,\n",
              " 53,\n",
              " 54,\n",
              " 19,\n",
              " 28,\n",
              " 53,\n",
              " 54,\n",
              " 43,\n",
              " 23,\n",
              " 28,\n",
              " 24,\n",
              " 1,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 9,\n",
              " 0,\n",
              " 24,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 43,\n",
              " 26,\n",
              " 28,\n",
              " 27,\n",
              " 50,\n",
              " 12,\n",
              " 39,\n",
              " 28,\n",
              " 54,\n",
              " 39,\n",
              " 52,\n",
              " 54,\n",
              " 0,\n",
              " 54,\n",
              " 52,\n",
              " 26,\n",
              " 28,\n",
              " 19,\n",
              " 54,\n",
              " 50,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 27,\n",
              " 43,\n",
              " 54,\n",
              " 21,\n",
              " 28,\n",
              " 23,\n",
              " 10,\n",
              " 10,\n",
              " 26,\n",
              " 10,\n",
              " 21,\n",
              " 24,\n",
              " 41,\n",
              " 54,\n",
              " 9,\n",
              " 4,\n",
              " 26,\n",
              " 50,\n",
              " 4,\n",
              " 54,\n",
              " 19,\n",
              " 0,\n",
              " 43,\n",
              " 27,\n",
              " 54,\n",
              " 43,\n",
              " 28,\n",
              " 26,\n",
              " 1,\n",
              " 1,\n",
              " 24,\n",
              " 53,\n",
              " 54,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 9,\n",
              " 0,\n",
              " 24,\n",
              " 54,\n",
              " 0,\n",
              " 54,\n",
              " 7,\n",
              " 26,\n",
              " 21,\n",
              " 41,\n",
              " 54,\n",
              " 7,\n",
              " 27,\n",
              " 27,\n",
              " 52,\n",
              " 33,\n",
              " 54,\n",
              " 19,\n",
              " 0,\n",
              " 10,\n",
              " 54,\n",
              " 9,\n",
              " 26,\n",
              " 12,\n",
              " 4,\n",
              " 54,\n",
              " 4,\n",
              " 0,\n",
              " 28,\n",
              " 43,\n",
              " 1,\n",
              " 33,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 33,\n",
              " 54,\n",
              " 10,\n",
              " 27,\n",
              " 50,\n",
              " 55,\n",
              " 41,\n",
              " 54,\n",
              " 0,\n",
              " 1,\n",
              " 12,\n",
              " 4,\n",
              " 39,\n",
              " 23,\n",
              " 21,\n",
              " 4,\n",
              " 54,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 43,\n",
              " 26,\n",
              " 43,\n",
              " 54,\n",
              " 4,\n",
              " 0,\n",
              " 31,\n",
              " 27,\n",
              " 54,\n",
              " 0,\n",
              " 54,\n",
              " 31,\n",
              " 27,\n",
              " 28,\n",
              " 33,\n",
              " 54,\n",
              " 1,\n",
              " 0,\n",
              " 28,\n",
              " 21,\n",
              " 27,\n",
              " 54,\n",
              " 19,\n",
              " 23,\n",
              " 24,\n",
              " 12,\n",
              " 0,\n",
              " 50,\n",
              " 4,\n",
              " 27,\n",
              " 53,\n",
              " 54,\n",
              " 19,\n",
              " 28,\n",
              " 24,\n",
              " 53,\n",
              " 54,\n",
              " 43,\n",
              " 23,\n",
              " 28,\n",
              " 24,\n",
              " 1,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 9,\n",
              " 0,\n",
              " 24,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 26,\n",
              " 10,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 43,\n",
              " 54,\n",
              " 7,\n",
              " 1,\n",
              " 39,\n",
              " 10,\n",
              " 43,\n",
              " 27,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 43,\n",
              " 54,\n",
              " 4,\n",
              " 0,\n",
              " 43,\n",
              " 54,\n",
              " 10,\n",
              " 27,\n",
              " 0,\n",
              " 28,\n",
              " 1,\n",
              " 33,\n",
              " 54,\n",
              " 12,\n",
              " 9,\n",
              " 26,\n",
              " 50,\n",
              " 27,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 23,\n",
              " 24,\n",
              " 23,\n",
              " 0,\n",
              " 1,\n",
              " 54,\n",
              " 0,\n",
              " 19,\n",
              " 39,\n",
              " 23,\n",
              " 10,\n",
              " 12,\n",
              " 54,\n",
              " 39,\n",
              " 52,\n",
              " 54,\n",
              " 10,\n",
              " 27,\n",
              " 50,\n",
              " 55,\n",
              " 41,\n",
              " 54,\n",
              " 9,\n",
              " 4,\n",
              " 26,\n",
              " 50,\n",
              " 4,\n",
              " 54,\n",
              " 50,\n",
              " 0,\n",
              " 19,\n",
              " 27,\n",
              " 54,\n",
              " 26,\n",
              " 10,\n",
              " 54,\n",
              " 31,\n",
              " 27,\n",
              " 28,\n",
              " 33,\n",
              " 54,\n",
              " 23,\n",
              " 24,\n",
              " 27,\n",
              " 52,\n",
              " 23,\n",
              " 1,\n",
              " 54,\n",
              " 0,\n",
              " 24,\n",
              " 54,\n",
              " 24,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 24,\n",
              " 20,\n",
              " 27,\n",
              " 10,\n",
              " 12,\n",
              " 54,\n",
              " 24,\n",
              " 39,\n",
              " 54,\n",
              " 19,\n",
              " 23,\n",
              " 50,\n",
              " 4,\n",
              " 54,\n",
              " 39,\n",
              " 52,\n",
              " 54,\n",
              " 4,\n",
              " 27,\n",
              " 28,\n",
              " 54,\n",
              " 12,\n",
              " 26,\n",
              " 19,\n",
              " 27,\n",
              " 54,\n",
              " 50,\n",
              " 28,\n",
              " 0,\n",
              " 10,\n",
              " 26,\n",
              " 10,\n",
              " 21,\n",
              " 54,\n",
              " 39,\n",
              " 31,\n",
              " 27,\n",
              " 28,\n",
              " 54,\n",
              " 21,\n",
              " 0,\n",
              " 28,\n",
              " 43,\n",
              " 27,\n",
              " 10,\n",
              " 54,\n",
              " 52,\n",
              " 27,\n",
              " 10,\n",
              " 50,\n",
              " 27,\n",
              " 24,\n",
              " 41,\n",
              " 54,\n",
              " 24,\n",
              " 20,\n",
              " 33,\n",
              " 26,\n",
              " 10,\n",
              " 21,\n",
              " 54,\n",
              " 39,\n",
              " 10,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 10,\n",
              " 27,\n",
              " 26,\n",
              " 21,\n",
              " 4,\n",
              " 7,\n",
              " 39,\n",
              " 28,\n",
              " 24,\n",
              " 53,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 43,\n",
              " 23,\n",
              " 28,\n",
              " 24,\n",
              " 1,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 24,\n",
              " 54,\n",
              " 4,\n",
              " 0,\n",
              " 43,\n",
              " 54,\n",
              " 0,\n",
              " 54,\n",
              " 24,\n",
              " 19,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 54,\n",
              " 24,\n",
              " 39,\n",
              " 10,\n",
              " 54,\n",
              " 50,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 27,\n",
              " 43,\n",
              " 54,\n",
              " 43,\n",
              " 23,\n",
              " 43,\n",
              " 1,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 43,\n",
              " 54,\n",
              " 26,\n",
              " 10,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 26,\n",
              " 28,\n",
              " 54,\n",
              " 39,\n",
              " 20,\n",
              " 26,\n",
              " 10,\n",
              " 26,\n",
              " 39,\n",
              " 10,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 28,\n",
              " 27,\n",
              " 54,\n",
              " 9,\n",
              " 0,\n",
              " 24,\n",
              " 54,\n",
              " 10,\n",
              " 39,\n",
              " 54,\n",
              " 52,\n",
              " 26,\n",
              " 10,\n",
              " 27,\n",
              " 28,\n",
              " 54,\n",
              " 7,\n",
              " 39,\n",
              " 33,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 33,\n",
              " 9,\n",
              " 4,\n",
              " 27,\n",
              " 28,\n",
              " 27,\n",
              " 53,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 43,\n",
              " 23,\n",
              " 28,\n",
              " 24,\n",
              " 1,\n",
              " 27,\n",
              " 33,\n",
              " 24,\n",
              " 54,\n",
              " 4,\n",
              " 0,\n",
              " 43,\n",
              " 54,\n",
              " 27,\n",
              " 31,\n",
              " 27,\n",
              " 28,\n",
              " 33,\n",
              " 12,\n",
              " 4,\n",
              " 26,\n",
              " 10,\n",
              " 21,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 9,\n",
              " 0,\n",
              " 10,\n",
              " 12,\n",
              " 27,\n",
              " 43,\n",
              " 41,\n",
              " 54,\n",
              " 7,\n",
              " 23,\n",
              " 12,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 0,\n",
              " 1,\n",
              " 24,\n",
              " 39,\n",
              " 54,\n",
              " 4,\n",
              " 0,\n",
              " 43,\n",
              " 54,\n",
              " 0,\n",
              " 54,\n",
              " 24,\n",
              " 27,\n",
              " 50,\n",
              " 28,\n",
              " 27,\n",
              " 12,\n",
              " 41,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 43,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 26,\n",
              " 28,\n",
              " 54,\n",
              " 21,\n",
              " 28,\n",
              " 27,\n",
              " 0,\n",
              " 12,\n",
              " 27,\n",
              " 24,\n",
              " 12,\n",
              " 54,\n",
              " 52,\n",
              " 27,\n",
              " 0,\n",
              " 28,\n",
              " 54,\n",
              " 9,\n",
              " 0,\n",
              " 24,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 0,\n",
              " 12,\n",
              " 54,\n",
              " 24,\n",
              " 39,\n",
              " 19,\n",
              " 27,\n",
              " 7,\n",
              " 39,\n",
              " 43,\n",
              " 33,\n",
              " 54,\n",
              " 9,\n",
              " 39,\n",
              " 23,\n",
              " 1,\n",
              " 43,\n",
              " 54,\n",
              " 43,\n",
              " 26,\n",
              " 24,\n",
              " 50,\n",
              " 39,\n",
              " 31,\n",
              " 27,\n",
              " 28,\n",
              " 54,\n",
              " 26,\n",
              " 12,\n",
              " 53,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 43,\n",
              " 26,\n",
              " 43,\n",
              " 10,\n",
              " 6,\n",
              " 12,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 26,\n",
              " 10,\n",
              " 55,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 50,\n",
              " 39,\n",
              " 23,\n",
              " 1,\n",
              " 43,\n",
              " 54,\n",
              " 7,\n",
              " 27,\n",
              " 0,\n",
              " 28,\n",
              " 54,\n",
              " 26,\n",
              " 12,\n",
              " 54,\n",
              " 26,\n",
              " 52,\n",
              " 54,\n",
              " 0,\n",
              " 10,\n",
              " 33,\n",
              " 39,\n",
              " 10,\n",
              " 27,\n",
              " 54,\n",
              " 52,\n",
              " 39,\n",
              " 23,\n",
              " 10,\n",
              " 43,\n",
              " 54,\n",
              " 39,\n",
              " 23,\n",
              " 12,\n",
              " 54,\n",
              " 0,\n",
              " 7,\n",
              " 39,\n",
              " 23,\n",
              " 12,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 54,\n",
              " 20,\n",
              " 39,\n",
              " 12,\n",
              " 12,\n",
              " 27,\n",
              " 28,\n",
              " 24,\n",
              " 53,\n",
              " 54,\n",
              " 19,\n",
              " 28,\n",
              " 24,\n",
              " 53,\n",
              " 54,\n",
              " 20,\n",
              " 39,\n",
              " 12,\n",
              " 12,\n",
              " 27,\n",
              " 28,\n",
              " 54,\n",
              " 9,\n",
              " 0,\n",
              " 24,\n",
              " 54,\n",
              " 19,\n",
              " 28,\n",
              " 24,\n",
              " 53,\n",
              " 54,\n",
              " 43,\n",
              " 23,\n",
              " 28,\n",
              " 24,\n",
              " 1,\n",
              " 27,\n",
              " 33,\n",
              " 6,\n",
              " 24,\n",
              " 54,\n",
              " 24,\n",
              " 26,\n",
              " 24,\n",
              " 12,\n",
              " 27,\n",
              " 28,\n",
              " 41,\n",
              " 54,\n",
              " 7,\n",
              " 23,\n",
              " 12,\n",
              " 54,\n",
              " 12,\n",
              " 4,\n",
              " 27,\n",
              " 33,\n",
              " 54,\n",
              " 4,\n",
              " 0,\n",
              " 43,\n",
              " 10,\n",
              " 6,\n",
              " 12,\n",
              " 54,\n",
              " 20]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_text[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfpYcaypKcI9"
      },
      "source": [
        "### Organizando y estructurando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WSSmg9jtKP0T"
      },
      "outputs": [],
      "source": [
        "# separaremos el dataset entre entrenamiento y validación.\n",
        "# `p_val` será la proporción del corpus que se reservará para validación\n",
        "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
        "p_val = 0.1\n",
        "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b7dCpGrdKll0"
      },
      "outputs": [],
      "source": [
        "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
        "train_text = tokenized_text[:-num_val*max_context_size]\n",
        "val_text = tokenized_text[-num_val*max_context_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NmxQdxl8LRCg"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_gyFT9koLqDm"
      },
      "outputs": [],
      "source": [
        "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oVNqmmLRodT0"
      },
      "outputs": [],
      "source": [
        "X = np.array(tokenized_sentences_train[:-1])\n",
        "y = np.array(tokenized_sentences_train[1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vken7O4ETsAJ"
      },
      "source": [
        "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
        "\n",
        "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
        "\n",
        "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
        "\n",
        "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
        "\n",
        "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3iPTx-UJl6r"
      },
      "source": [
        "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFAyA4zCWE-5",
        "outputId": "c2790c9a-0264-467a-a440-fa4a9e326af8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(413063, 100)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKRl70HFTzG",
        "outputId": "175e77f0-621b-4c23-e0f0-0612fdc411ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([54, 12,  4, 27, 54,  7, 39, 33, 54,  9])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVpLCKSZFXZO",
        "outputId": "e9c3d143-f693-43cf-ec0c-113b878bdde1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([12,  4, 27, 54,  7, 39, 33, 54,  9,  4])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0,:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOFCR-KqbW1N",
        "outputId": "3c8d7138-2b45-4923-ac1f-8bfc9db2b4f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 57\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(chars_vocab)\n",
        "print(\"Vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnnjdAQ5UAEJ"
      },
      "source": [
        "# Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rkMCZvmhrQz4"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense, GRU\n",
        "from keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgz7VKwTUbj6"
      },
      "source": [
        "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia.\n",
        "\n",
        "Sumado al modelo original propuesto en clases, voy a crear dos modelos adicionales: LSTM y GRU. Dada la experiencia pasada y el gran coste computacional de entrenar estos modelos, se utilizarán menos conexiones en las capas para su entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeMQBMbvt9st"
      },
      "source": [
        "### Modelo simpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "Zd2OkfQYs2Q7",
        "outputId": "218debbf-da8c-4608-cfdf-80206968403c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,457</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)           │          \u001b[38;5;34m51,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)            │          \u001b[38;5;34m11,457\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,057</span> (246.32 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,057\u001b[0m (246.32 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,057</span> (246.32 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,057\u001b[0m (246.32 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uewX4yBat9st"
      },
      "source": [
        "### Modelo LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "nAHY0H1Vt9st",
        "outputId": "bdc91920-5de2-4d8b-b08c-f479a47ec616"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">63,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,757</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_1 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │          \u001b[38;5;34m63,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)            │           \u001b[38;5;34m5,757\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,957</span> (269.36 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,957\u001b[0m (269.36 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,957</span> (269.36 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,957\u001b[0m (269.36 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_lstm = Sequential()\n",
        "\n",
        "model_lstm.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_lstm.add(LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_lstm.add(Dense(vocab_size, activation='softmax'))\n",
        "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dm2_kKTt9st"
      },
      "source": [
        "### Modelo GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "VNl2OYiVt9st",
        "outputId": "a413cdbd-dfa5-4bfa-aab8-1826cbcb78aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">47,700</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,757</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ time_distributed_2 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)           │          \u001b[38;5;34m47,700\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)            │           \u001b[38;5;34m5,757\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,457</span> (208.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m53,457\u001b[0m (208.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,457</span> (208.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m53,457\u001b[0m (208.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_gru = Sequential()\n",
        "\n",
        "model_gru.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
        "model_gru.add(GRU(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
        "model_gru.add(Dense(vocab_size, activation='softmax'))\n",
        "model_gru.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "model_gru.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmJWNyxQwfCE"
      },
      "source": [
        "\n",
        "### Definir el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWK3z85sQfUe"
      },
      "source": [
        "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
        "\n",
        "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zUHX3r5JD-MG"
      },
      "outputs": [],
      "source": [
        "class PplCallback(keras.callbacks.Callback):\n",
        "\n",
        "    '''\n",
        "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
        "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
        "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
        "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
        "    si la perplejidad no mejora después de `patience` epochs.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, val_data, history_ppl,patience=5, model_name='best_model'):\n",
        "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
        "      # mediremos la perplejidad\n",
        "      self.val_data = val_data\n",
        "\n",
        "      self.target = []\n",
        "      self.padded = []\n",
        "\n",
        "      count = 0\n",
        "      self.info = []\n",
        "      self.min_score = np.inf\n",
        "      self.patience_counter = 0\n",
        "      self.patience = patience\n",
        "      self.model_name = model_name\n",
        "      self.history_ppl = history_ppl\n",
        "\n",
        "      # nos movemos en todas las secuencias de los datos de validación\n",
        "      for seq in self.val_data:\n",
        "\n",
        "        len_seq = len(seq)\n",
        "        # armamos todas las subsecuencias\n",
        "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
        "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
        "\n",
        "        if len(subseq)!=0:\n",
        "\n",
        "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
        "\n",
        "          self.info.append((count,count+len_seq))\n",
        "          count += len_seq\n",
        "\n",
        "      self.padded = np.vstack(self.padded)\n",
        "\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "\n",
        "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
        "        scores = []\n",
        "\n",
        "        predictions = self.model.predict(self.padded,verbose=0)\n",
        "\n",
        "        # para cada secuencia de validación\n",
        "        for start,end in self.info:\n",
        "\n",
        "          # en `probs` iremos guardando las probabilidades de los términos target\n",
        "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
        "\n",
        "          # calculamos la perplejidad por medio de logaritmos\n",
        "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
        "\n",
        "        # promediamos todos los scores e imprimimos el valor promedio\n",
        "        current_score = np.mean(scores)\n",
        "        self.history_ppl.append(current_score)\n",
        "        print(f'\\n mean perplexity: {current_score} \\n')\n",
        "\n",
        "        # chequeamos si tenemos que detener el entrenamiento\n",
        "        if current_score < self.min_score:\n",
        "          self.min_score = current_score\n",
        "          save_path = f'drive/MyDrive/Colab Notebooks/desafio_3/{self.model_name}.keras'\n",
        "          self.model.save(save_path) #my_model.h5\n",
        "          print(f\"Saved new model: {self.model_name}.keras\")\n",
        "          self.patience_counter = 0\n",
        "        else:\n",
        "          self.patience_counter += 1\n",
        "          if self.patience_counter == self.patience:\n",
        "            print(\"Stopping training...\")\n",
        "            self.model.stop_training = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HBZIwR0gruA"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn6qyqKkt9sw"
      },
      "source": [
        "#### Entrenamiento simpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQq1PHDkxDvN",
        "outputId": "45ab024f-f9a4-4478-8153-8d7c6bf678b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3534\n",
            " mean perplexity: 5.589537286103571 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 34ms/step - loss: 2.3533\n",
            "Epoch 2/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.7906\n",
            " mean perplexity: 4.885896100435235 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.7906\n",
            "Epoch 3/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6876\n",
            " mean perplexity: 4.729709749915466 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.6876\n",
            "Epoch 4/20\n",
            "\u001b[1m1611/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6464\n",
            " mean perplexity: 4.648607036571634 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.6464\n",
            "Epoch 5/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6211\n",
            " mean perplexity: 4.530915772601736 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.6211\n",
            "Epoch 6/20\n",
            "\u001b[1m1611/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6055\n",
            " mean perplexity: 4.498269187982869 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.6055\n",
            "Epoch 7/20\n",
            "\u001b[1m1613/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5948\n",
            " mean perplexity: 4.489183802678399 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.5948\n",
            "Epoch 8/20\n",
            "\u001b[1m1613/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5866\n",
            " mean perplexity: 4.368963293053095 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.5866\n",
            "Epoch 9/20\n",
            "\u001b[1m1613/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5790\n",
            " mean perplexity: 4.3790417521094565 \n",
            "\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.5790\n",
            "Epoch 10/20\n",
            "\u001b[1m1611/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5740\n",
            " mean perplexity: 4.321705946999909 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 28ms/step - loss: 1.5740\n",
            "Epoch 11/20\n",
            "\u001b[1m1613/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5701\n",
            " mean perplexity: 4.306948678348155 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - loss: 1.5701\n",
            "Epoch 12/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5655\n",
            " mean perplexity: 4.297105338587828 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - loss: 1.5655\n",
            "Epoch 13/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5613\n",
            " mean perplexity: 4.2505843565718076 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - loss: 1.5613\n",
            "Epoch 14/20\n",
            "\u001b[1m1613/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5587\n",
            " mean perplexity: 4.276857734414394 \n",
            "\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - loss: 1.5587\n",
            "Epoch 15/20\n",
            "\u001b[1m1611/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.5559\n",
            " mean perplexity: 4.230248442850364 \n",
            "\n",
            "Saved new model: model_simpleRNN.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - loss: 1.5559\n"
          ]
        }
      ],
      "source": [
        "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
        "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
        "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
        "history_ppl = []\n",
        "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl, model_name='model_simpleRNN')], batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBsqIkHBxzvN"
      },
      "source": [
        "#### Entrenamiento LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud8RMDHYxzNy",
        "outputId": "b5e971f2-034c-4745-96f5-536411e0a3e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.7263\n",
            " mean perplexity: 8.586886073555608 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 147ms/step - loss: 2.7262\n",
            "Epoch 2/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 2.1833\n",
            " mean perplexity: 7.1592440669760835 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 146ms/step - loss: 2.1833\n",
            "Epoch 3/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 2.0375\n",
            " mean perplexity: 6.3657185465364545 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 146ms/step - loss: 2.0375\n",
            "Epoch 4/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.9487\n",
            " mean perplexity: 5.88493669165991 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 145ms/step - loss: 1.9487\n",
            "Epoch 5/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.8925\n",
            " mean perplexity: 5.591976333933238 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 144ms/step - loss: 1.8925\n",
            "Epoch 6/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.8539\n",
            " mean perplexity: 5.394154624671091 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 146ms/step - loss: 1.8539\n",
            "Epoch 7/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.8262\n",
            " mean perplexity: 5.2527963221082885 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 146ms/step - loss: 1.8262\n",
            "Epoch 8/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.8075\n",
            " mean perplexity: 5.160025110909153 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 145ms/step - loss: 1.8075\n",
            "Epoch 9/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.7923\n",
            " mean perplexity: 5.079291281277288 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 145ms/step - loss: 1.7923\n",
            "Epoch 10/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.7793\n",
            " mean perplexity: 5.023216472225087 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 145ms/step - loss: 1.7793\n",
            "Epoch 11/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.7686\n",
            " mean perplexity: 4.989190820699406 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 145ms/step - loss: 1.7686\n",
            "Epoch 12/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.7590\n",
            " mean perplexity: 4.986355393320211 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 145ms/step - loss: 1.7590\n",
            "Epoch 13/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.7491\n",
            " mean perplexity: 4.964170976433986 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 150ms/step - loss: 1.7491\n",
            "Epoch 14/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.7381\n",
            " mean perplexity: 4.940569923688186 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 154ms/step - loss: 1.7381\n",
            "Epoch 15/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1.7289\n",
            " mean perplexity: 4.933642263629879 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 151ms/step - loss: 1.7289\n",
            "Epoch 16/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.7196\n",
            " mean perplexity: 4.917829149615281 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 154ms/step - loss: 1.7196\n",
            "Epoch 17/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.7115\n",
            " mean perplexity: 4.886698369688592 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 153ms/step - loss: 1.7115\n",
            "Epoch 18/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.7048\n",
            " mean perplexity: 4.8543542103308885 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 153ms/step - loss: 1.7048\n",
            "Epoch 19/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.6978\n",
            " mean perplexity: 4.796491839040855 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 153ms/step - loss: 1.6978\n",
            "Epoch 20/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 1.6900\n",
            " mean perplexity: 4.783208406944184 \n",
            "\n",
            "Saved new model: model_lstm.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 153ms/step - loss: 1.6900\n"
          ]
        }
      ],
      "source": [
        "history_ppl_lstm = []\n",
        "hist_lstm = model_lstm.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl_lstm, model_name='model_lstm')], batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApTjdwTvx9Yu"
      },
      "source": [
        "#### Entrenamiento GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umvZm6vCySKG",
        "outputId": "4af0bd7e-3585-446b-ccd9-b9f54a7ef5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 2.5035\n",
            " mean perplexity: 5.84204279590027 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 202ms/step - loss: 2.5033\n",
            "Epoch 2/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.8259\n",
            " mean perplexity: 5.02090861294786 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 201ms/step - loss: 1.8259\n",
            "Epoch 3/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.7115\n",
            " mean perplexity: 4.732996954623499 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 204ms/step - loss: 1.7115\n",
            "Epoch 4/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.6615\n",
            " mean perplexity: 4.667749585836112 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 201ms/step - loss: 1.6615\n",
            "Epoch 5/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.6316\n",
            " mean perplexity: 4.615972640204875 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 201ms/step - loss: 1.6316\n",
            "Epoch 6/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.6119\n",
            " mean perplexity: 4.566666811039602 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 200ms/step - loss: 1.6119\n",
            "Epoch 7/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.5975\n",
            " mean perplexity: 4.540813805151707 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 200ms/step - loss: 1.5975\n",
            "Epoch 8/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.5864\n",
            " mean perplexity: 4.504897650678284 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 201ms/step - loss: 1.5864\n",
            "Epoch 9/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.5775\n",
            " mean perplexity: 4.491373123340832 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 201ms/step - loss: 1.5775\n",
            "Epoch 10/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.5700\n",
            " mean perplexity: 4.501568874223032 \n",
            "\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 201ms/step - loss: 1.5700\n",
            "Epoch 11/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 1.5635\n",
            " mean perplexity: 4.467216010866189 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 201ms/step - loss: 1.5635\n",
            "Epoch 12/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.5584\n",
            " mean perplexity: 4.456233827365841 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 202ms/step - loss: 1.5584\n",
            "Epoch 13/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.5539\n",
            " mean perplexity: 4.464516044112273 \n",
            "\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 200ms/step - loss: 1.5539\n",
            "Epoch 14/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.5485\n",
            " mean perplexity: 4.430919849087345 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 200ms/step - loss: 1.5485\n",
            "Epoch 15/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.5451\n",
            " mean perplexity: 4.427868073862697 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 200ms/step - loss: 1.5451\n",
            "Epoch 16/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 1.5408\n",
            " mean perplexity: 4.405871361879045 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 198ms/step - loss: 1.5408\n",
            "Epoch 17/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 1.5372\n",
            " mean perplexity: 4.444201291682439 \n",
            "\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 198ms/step - loss: 1.5372\n",
            "Epoch 18/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 1.5357\n",
            " mean perplexity: 4.416455309932965 \n",
            "\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 192ms/step - loss: 1.5357\n",
            "Epoch 19/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 1.5319\n",
            " mean perplexity: 4.433608743265987 \n",
            "\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 190ms/step - loss: 1.5319\n",
            "Epoch 20/20\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 1.5268\n",
            " mean perplexity: 4.405344627800549 \n",
            "\n",
            "Saved new model: model_gru.keras\n",
            "\u001b[1m1614/1614\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 195ms/step - loss: 1.5268\n"
          ]
        }
      ],
      "source": [
        "history_ppl_GRU = []\n",
        "hist_gru = model_gru.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl_GRU, model_name='model_gru')], batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "zlJVS4ux5ec0",
        "outputId": "7f41ffe0-a8e4-4374-9e5e-d8ce980d63ff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAAIjCAYAAADFthA8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACQkUlEQVR4nOzdd3gUVdsG8Hu2b9qmE1IgEDpEiiAqvSgoFhQQUOn46it8iIoilpeiUkSxd6oCggWxgXQEUXoRpEOAUAPpdev5/tjsJptG6k42uX/XNddOOTv77CaB3DlnzkhCCAEiIiIiIqJaQiF3AURERERERO7EEERERERERLUKQxAREREREdUqDEFERERERFSrMAQREREREVGtwhBERERERES1CkMQERERERHVKgxBRERERERUqzAEERERERFRrcIQREQVJkkSpk2bVqnnXLx4MSRJwrlz5yr1vJVt7ty5aNiwIZRKJdq0aSN3OWUybdo0SJJUpa9RFd8bVHFbt26FJEnYunWr3KVUiMViwYsvvoioqCgoFAr0799f7pIKqci/Ze74GSWqrRiCiGoIx3+0xS07d+6Uu8QizZw5E6tXr5a7jHJZv349XnzxRXTq1AmLFi3CzJkzi207cuRIl6+Hn58fWrdujXfeeQdGo9GNVcvrr7/+wrRp05CSkiJ3Kdi6dSsefvhhhIWFQaPRIDQ0FPfffz9WrVold2lUSgsXLsTcuXMxcOBALFmyBM8++2yxbbt37w5JktC4ceMij2/YsMH58/n9999XVclEVE2o5C6AiCrXjBkz0KBBg0L7GzVqJEM1Nzdz5kwMHDiw0F9whw0bhiFDhkCr1cpTWCls3rwZCoUCCxYsgEajuWl7rVaL+fPnAwBSUlLwww8/YNKkSdizZw9WrFhR1eXKIjs7GypV3n81f/31F6ZPn46RI0fC399ftrqmTp2KGTNmoHHjxnjyySdRv359JCYmYs2aNRgwYACWLVuGRx99VLb6qlrXrl2RnZ1dqu/b6mzz5s2IiIjAu+++W6r2Op0Op0+fxu7du3Hbbbe5HFu2bBl0Oh1ycnKqolQiqmYYgohqmHvuuQft27eXu4wKUyqVUCqVcpdRooSEBOj1+lL/IqlSqfD44487t59++ml07NgRK1euxLx58xAeHl7uWmw2G0wmE3Q6XbnPURWqWz0A8P3332PGjBkYOHAgli9fDrVa7Tz2wgsvYN26dTCbzTJWWHVycnKg0WigUCiq5demrBISEsoUpmNiYmCxWPDNN9+4hKCcnBz8+OOP6NevH3744YcqqJSIqhsOhyOqRcxmMwIDAzFq1KhCx9LS0qDT6TBp0iTnvoSEBIwZMwZ16tSBTqdD69atsWTJkpu+zsiRIxEdHV1of8Hx7ZIkITMzE0uWLHEOQxk5ciSA4sfRf/LJJ2jZsiW0Wi3Cw8Mxbty4QkOrunfvjlatWuHo0aPo0aMHvLy8EBERgbfeeuumtQP26wxef/11xMTEQKvVIjo6Gi+//LLLsDVJkrBo0SJkZmY6a1+8eHGpzu+gUCjQvXt3AHC+T6PRiKlTp6JRo0bQarWIiorCiy++WGjInCRJGD9+PJYtW+b8PH7//XecO3cOkiTh7bffxrvvvov69etDr9ejW7duOHLkSKnqWrp0KW699Vbo9XoEBgZiyJAhiI+Pdx5ftGgRJEnCwoULXZ43c+ZMSJKENWvWuNTpuCZo2rRpeOGFFwAADRo0cH5u586dQ7du3dC6desi62natCn69OlTqtpL47XXXkNgYCAWLlzoEoAc+vTpg/vuu8+5XZqfg/yf+8cff4yGDRvCy8sLd999N+Lj4yGEwOuvv47IyEjo9Xo8+OCDSEpKcjlHdHQ07rvvPqxfvx5t2rSBTqdDixYtCg3PS0pKwqRJkxAbGwsfHx/4+fnhnnvuwaFDh1zaOa77WbFiBV599VVERETAy8sLaWlpRV4TdOrUKQwYMABhYWHQ6XSIjIzEkCFDkJqa6mxTmp+N/O/lzz//xG233QadToeGDRviq6++KtXXKDMzE88//zyioqKg1WrRtGlTvP322xBCuHzeW7Zswb///uv8XirNNU5Dhw7FypUrYbPZnPt++eUXZGVl4ZFHHinyOQcOHMA999wDPz8/+Pj4oFevXkUOMf7333/Rs2dP6PV6REZG4o033nB5nfzWrl2LLl26wNvbG76+vujXrx/+/fffm9a/YcMGdO7cGf7+/vDx8UHTpk3x8ssv3/R5RFSAIKIaYdGiRQKA2Lhxo7h+/brLcuPGDWe70aNHC39/f2E0Gl2ev2TJEgFA7NmzRwghRFZWlmjevLlQq9Xi2WefFR988IHo0qWLACDee+89l+cCEFOnTnVujxgxQtSvX79QjVOnThX5/9n5+uuvhVarFV26dBFff/21+Prrr8Vff/3l8n7i4uIKPb93797iww8/FOPHjxdKpVJ06NBBmEwmZ7tu3bqJ8PBwERUVJZ555hnxySefiJ49ewoAYs2aNTf9LEeMGCEAiIEDB4qPP/5YDB8+XAAQ/fv3d6m9S5cuQqvVOms/c+ZMief09vYutP+hhx4SAMTx48eF1WoVd999t/Dy8hITJ04Un3/+uRg/frxQqVTiwQcfdHkeANG8eXMREhIipk+fLj7++GNx4MABERcXJwCI2NhYER0dLebMmSOmT58uAgMDRUhIiLh69WqxXw8hhHjjjTeEJEli8ODB4pNPPhHTp08XwcHBIjo6WiQnJzvb3XfffcJgMIgLFy4IIYT4559/hEajEWPGjClUp+N749ChQ2Lo0KECgHj33Xedn1tGRob48ssvBQBx+PBhl+fv3r1bABBfffVVsZ9tWZw8eVIAEKNHjy5V+9L+HDg+9zZt2ogWLVqIefPmiVdffVVoNBpx++23i5dfflnceeed4oMPPhATJkwQkiSJUaNGubxW/fr1RZMmTYS/v7946aWXxLx580RsbKxQKBRi/fr1znZ79uwRMTEx4qWXXhKff/65mDFjhoiIiBAGg0FcunTJ2W7Lli0CgGjRooVo06aNmDdvnpg1a5bIzMx0HtuyZYsQQgij0SgaNGggwsPDxRtvvCHmz58vpk+fLjp06CDOnTvnPGdpfjYc76Vp06aiTp064uWXXxYfffSRaNeunZAkSRw5cqTEz9xms4mePXsKSZLE2LFjxUcffSTuv/9+AUBMnDhRCCFERkaG+Prrr0WzZs1EZGSk83sp//d3Qd26dRMtW7Z0fg9s2rTJeax///6iT58+zs/lu+++cx47cuSI8Pb2FnXr1hWvv/66mD17tmjQoIHQarVi586dznZXrlwRISEhIiAgQEybNk3MnTtXNG7cWNxyyy2F/i376quvhCRJom/fvuLDDz8Uc+bMEdHR0cLf37/If/Py16LRaET79u3F+++/Lz777DMxadIk0bVr1xI/UyIqjCGIqIZwhIaiFq1W62y3bt06AUD88ssvLs+/9957RcOGDZ3b7733ngAgli5d6txnMpnEHXfcIXx8fERaWppzf3lDkBBCeHt7ixEjRhT7fhy/ECQkJAiNRiPuvvtuYbVane0++ugjAUAsXLjQua9bt26FfnE2Go0iLCxMDBgwoNBr5Xfw4EEBQIwdO9Zl/6RJkwQAsXnzZpf3WVSwKYqjrSOYnj59WsycOVNIkiRuueUWIYQ9WCkUCrF9+3aX53722WcCgNixY4dzHwChUCjEv//+69LW8cu4Xq8XFy9edO7ftWuXACCeffZZ576CX49z584JpVIp3nzzTZdzHj58WKhUKpf9V65cEYGBgeKuu+4SRqNRtG3bVtSrV0+kpqa6PLfg98bcuXML/UIohBApKSlCp9OJyZMnu+yfMGGC8Pb2FhkZGYU+0/L46aefnCGsNEr7c+D43ENCQkRKSoqz7ZQpUwQA0bp1a2E2m537hw4dKjQajcjJyXHuq1+/vgAgfvjhB+e+1NRUUbduXdG2bVvnvpycHJefAcfra7VaMWPGDOc+xy/0DRs2FFlZWS7tC4agAwcOFPrlv6Cy/Gw43su2bduc+xISEoRWqxXPP/98sa8hhBCrV68WAMQbb7zhsn/gwIFCkiRx+vRp5z5HsCmN/G3bt2/vDOzJyclCo9GIJUuWFBmC+vfvLzQajcsfOS5fvix8fX1dwsfEiRMFALFr1y6X92wwGFy+59PT04W/v7944oknXOq7evWqMBgMLvsL/oy+++67AoC4fv16qd4zERWPw+GIapiPP/4YGzZscFnWrl3rPN6zZ08EBwdj5cqVzn3JycnYsGEDBg8e7Ny3Zs0ahIWFYejQoc59arUaEyZMQEZGBv744w/3vKFcGzduhMlkwsSJE6FQ5P3T9cQTT8DPzw+//fabS3sfHx+X6280Gg1uu+02nD17tsTXcQzleu6551z2P//88wBQ6HXKIjMzEyEhIQgJCUGjRo3w8ssv44477sCPP/4IAPjuu+/QvHlzNGvWDDdu3HAuPXv2BABs2bLF5XzdunVDixYtinyt/v37IyIiwrl92223oWPHji5D1QpatWoVbDYbHnnkEZfXDwsLQ+PGjV1ePywszPm91qVLFxw8eBALFy6En59fuT4bg8GABx98EN98841zyJPVasXKlSvRv39/eHt7l+u8BaWlpQEAfH19S9W+rD8HgwYNgsFgcG537NgRAPD444+7TBDRsWNHmEwmXLp0yeX54eHheOihh5zbfn5+GD58OA4cOICrV68CsE+w4fgZsFqtSExMdA6L2r9/f6H3MGLECOj1+hLfp6PmdevWISsrq9jPAij9z0aLFi3QpUsX53ZISAiaNm1aqp9BpVKJCRMmFHodIYTLv2fl9eijj2LVqlUwmUz4/vvvoVQqXT53B6vVivXr16N///5o2LChc3/dunXx6KOP4s8//3R+T61Zswa33367y7VGISEheOyxx1zOuWHDBqSkpGDo0KEuP2dKpRIdO3Ys9HOen+P6p59++qnYYXZEVDqcGIGohrnttttKnBhBpVJhwIABWL58OYxGI7RaLVatWgWz2ewSgs6fP4/GjRu7BA4AaN68ufO4Ozler2nTpi77NRoNGjZsWKieyMjIQvfXCAgIwD///HPT11EoFIVm0wsLC4O/v3+F3rdOp8Mvv/wCwP6LbIMGDRAZGek8furUKRw7dgwhISFFPj8hIcFlu6hZAB2Kmga4SZMm+Pbbb4t9zqlTpyCEKHYK4YLXzwwZMgRLly7Fb7/9hv/85z/o1atXsecujeHDh2PlypXYvn07unbtio0bN+LatWsYNmxYic9LTU1Fdna2c1uj0SAwMLDIto6Qlp6eXqqayvpzUK9ePZdtR7iIiooqcn9ycrLL/kaNGhX6vm3SpAkA+3UwYWFhsNlseP/99/HJJ58gLi4OVqvV2TYoKKjQeyjp+yR/m+eeew7z5s3DsmXL0KVLFzzwwAN4/PHHnbWW9Wej4GcB2H8GC77ngs6fP4/w8PBCQbUy/+0ZMmQIJk2ahLVr12LZsmW47777igzG169fR1ZWVqF/dxz12Gw2xMfHo2XLljh//rwz9OZX8LmnTp0CAOcfNwoq6Q8JgwcPxvz58zF27Fi89NJL6NWrFx5++GEMHDiw0PcoEZWMIYioFhoyZAg+//xzrF27Fv3798e3336LZs2aFXthelkVd3O//L+sVbXiZpZz9DLcTFXcoFCpVKJ3797FHrfZbIiNjcW8efOKPF7wF+mb/XW/rGw2GyRJwtq1a4v8/Hx8fFy2ExMTsXfvXgDA0aNHYbPZKvSLWJ8+fVCnTh0sXboUXbt2xdKlSxEWFlbiZwYAzzzzjMtEBd26dSv2AvlmzZoBAA4fPlzuOktS3PddRb8f85s5cyZee+01jB49Gq+//joCAwOhUCgwceLEInsHSvt98s4772DkyJH46aefsH79ekyYMAGzZs3Czp07XcJ6aX82KvM9V7a6deuie/fueOedd7Bjxw63zgjn+Bp9/fXXCAsLK3Q8f49hQXq9Htu2bcOWLVvw22+/4ffff8fKlSvRs2dPrF+/vtrPqElUnTAEEdVCXbt2Rd26dbFy5Up07twZmzdvxiuvvOLSpn79+vjnn38K/WJ7/Phx5/HiBAQEFHkzzKL+glvaX6gcr3fixAmXYSkmkwlxcXE3/UW5tOrXrw+bzYZTp045//IMANeuXUNKSkqJ77uiYmJicOjQIfTq1avCIczx1+b8Tp48WeSsfflfXwiBBg0aOHsfSjJu3Dikp6dj1qxZmDJlCt57771CQ6UKKul9KZVKPProo1i8eDHmzJmD1atX44knnrjpL3Yvvviiy9DHgICAYts2adIETZs2xU8//YT333+/ULArqCI/B+Vx+vRpCCFcPqeTJ08CgPNr9/3336NHjx5YsGCBy3NTUlIQHBxcodePjY1FbGwsXn31Vfz111/o1KkTPvvsM7zxxhtu+9moX78+Nm7ciPT0dJfemcr+zB999FGMHTsW/v7+uPfee4tsExISAi8vL5w4caLQsePHj0OhUDj/OFG/fv0if+4KPjcmJgYAEBoaWq5/txQKBXr16oVevXph3rx5mDlzJl555RVs2bKl0v4dJKoN2HdKVAspFAoMHDgQv/zyC77++mtYLBaXoXAAcO+99+Lq1asu1w5ZLBZ8+OGH8PHxQbdu3Yo9f0xMDFJTU12Gnl25csV57Ut+3t7eRQamgnr37g2NRoMPPvjA5S/JCxYsQGpqKvr163fTc5SG45eh9957z2W/o3emsl6nKI888gguXbqEL7/8stCx7OxsZGZmlvpcq1evdrneZPfu3di1axfuueeeYp/z8MMPQ6lUYvr06YX+Wi+EQGJionP7+++/x8qVKzF79my89NJLGDJkCF599VXnL+zFcVzbU9zXfNiwYUhOTsaTTz6JjIwMl3BTnBYtWqB3797O5dZbby2x/fTp05GYmIixY8fCYrEUOr5+/Xr8+uuvACr2c1Aely9fdvk5SUtLw1dffYU2bdo4ew2USmWhr893331X6PqiskhLSyv0WcTGxkKhUDinv3bXz8a9994Lq9WKjz76yGX/u+++C0mSSvweLouBAwdi6tSp+OSTT4q915dSqcTdd9+Nn376yWW6/mvXrmH58uXo3Lmzc/javffei507d2L37t3OdtevX8eyZctcztmnTx/4+flh5syZRd6P6vr168XWXHBadQBo06YNABSappyISsaeIKIaZu3atc6/mOZ35513uvSgDB48GB9++CGmTp2K2NhYl7/sAsB//vMffP755xg5ciT27duH6OhofP/999ixYwfee++9Ei8sHzJkCCZPnoyHHnoIEyZMQFZWFj799FM0adKk0IXbt956KzZu3Oi8WWiDBg2KHFcfEhKCKVOmYPr06ejbty8eeOABnDhxAp988gk6dOhQql+WS6N169YYMWIEvvjiC6SkpKBbt27YvXs3lixZgv79+6NHjx6V8jpFGTZsGL799ls89dRT2LJlCzp16gSr1Yrjx4/j22+/xbp160p9I9xGjRqhc+fO+O9//wuj0Yj33nsPQUFBePHFF4t9TkxMDN544w1MmTIF586dQ//+/eHr64u4uDj8+OOP+M9//oNJkyYhISEB//3vf9GjRw+MHz8eAPDRRx9hy5YtGDlyJP78889ih8U5Asorr7yCIUOGQK1W4/7773eGo7Zt26JVq1bOSSLatWtXlo+wVAYPHozDhw/jzTffxIEDBzB06FDUr18fiYmJ+P3337Fp0yYsX74cQMV+DsqjSZMmGDNmDPbs2YM6depg4cKFuHbtGhYtWuRsc99992HGjBkYNWoU7rzzThw+fBjLli1z+fkuq82bN2P8+PEYNGgQmjRpAovFgq+//hpKpRIDBgwA4L6fjfvvvx89evTAK6+8gnPnzqF169ZYv349fvrpJ0ycONHZk1JRBoPBeQ+rkrzxxhvOe/M8/fTTUKlU+Pzzz2E0Gl3uPfbiiy/i66+/Rt++ffHMM8/A29sbX3zxhbM30cHPzw+ffvophg0bhnbt2mHIkCEICQnBhQsX8Ntvv6FTp06FAqDDjBkzsG3bNvTr1w/169dHQkICPvnkE0RGRqJz584V/kyIahV5JqUjospW0hTZAMSiRYtc2ttsNhEVFVXkVLQO165dE6NGjRLBwcFCo9GI2NjYQucRovA0yEIIsX79etGqVSuh0WhE06ZNxdKlS4ucIvv48eOia9euQq/XCwDO6bKLuk+QEPYpsZs1aybUarWoU6eO+O9//+ty/xohip82t7ipuwsym81i+vTpokGDBkKtVouoqCgxZcoUl+mMHecr6xTZN2MymcScOXNEy5YthVarFQEBAeLWW28V06dPd5l+GoAYN25coec7pmqeO3eueOedd0RUVJTzXkyHDh1yaVvU10MIIX744QfRuXNn4e3tLby9vUWzZs3EuHHjxIkTJ4QQQjz88MPC19fX5f4xQuRNPz1nzhyXOgt+b7z++usiIiJCKBSKIr/Gb731lgAgZs6cedPPqyI2bdokHnzwQREaGipUKpUICQkR999/v/jpp59c2pXm5yD/555fUVMuC5H3/e24L5cQ9mml+/XrJ9atWyduueUWodVqRbNmzQo9NycnRzz//POibt26Qq/Xi06dOom///5bdOvWTXTr1u2mr53/mGOK7LNnz4rRo0eLmJgYodPpRGBgoOjRo4fYuHGjy/NK+7PheC8FFayxOOnp6eLZZ58V4eHhQq1Wi8aNG4u5c+cKm81W6HzlmSK7OMV9Zvv37xd9+vQRPj4+wsvLS/To0cN5T7P8/vnnH9GtWzeh0+lERESEeP3118WCBQuK/D7fsmWL6NOnjzAYDEKn04mYmBgxcuRIsXfvXmebgj+jju/Z8PBwodFoRHh4uBg6dKg4efJkqT4DIsojCVENrlAkIqJKce7cOTRo0ABz587FpEmT5C6nXN5//308++yzOHfuXJEzjNVU0dHRaNWqlXMoHhERVR1eE0RERNWGEAILFixAt27dalUAIiIi9+I1QUREJLvMzEz8/PPP2LJlCw4fPoyffvpJ7pKIiKgGYwgiIiLZXb9+HY8++ij8/f3x8ssv44EHHpC7JCIiqsF4TRAREREREdUqvCaIiIiIiIhqFYYgIiIiIiKqVTz6miCbzYbLly/D19cXkiTJXQ4REREREclECIH09HSEh4cXe9NuB48OQZcvX0ZUVJTcZRARERERUTURHx+PyMjIEtt4dAjy9fUFYH+jfn5+MldDRERERERySUtLQ1RUlDMjlMSjQ5BjCJyfnx9DEBERERERleoyGU6MQEREREREtQpDEBERERER1SoMQUREREREVKt49DVBRERERFQ7CSFgsVhgtVrlLoXcRKlUQqVSVcqtcRiCiIiIiMijmEwmXLlyBVlZWXKXQm7m5eWFunXrQqPRVOg8DEFERERE5DFsNhvi4uKgVCoRHh4OjUZTKT0DVL0JIWAymXD9+nXExcWhcePGN70hakkYgoiIiIjIY5hMJthsNkRFRcHLy0vucsiN9Ho91Go1zp8/D5PJBJ1OV+5zcWIEIiIiIvI4FekFIM9VWV93fvcQEREREVGtwhBERERERES1CkMQEREREVE1IUkSVq9eXeWv0717d0ycOLHKX6e6YggiIiIiInKT69ev47///S/q1asHrVaLsLAw9OnTBzt27AAAXLlyBffcc4/MVRa2detWSJLkXEJCQnDvvffi8OHDLu1GjhwJSZIwe/Zsl/2rV692mcXPcb6WLVsWuteTv78/Fi9eXGXvBWAIIiIiIiJymwEDBuDAgQNYsmQJTp48iZ9//hndu3dHYmIiACAsLAxarVbmKot34sQJXLlyBevWrYPRaES/fv1gMplc2uh0OsyZMwfJyck3Pd/Zs2fx1VdfVVW5xWIIIiIiIiKPJoRAlskiyyKEKHWdKSkp2L59O+bMmYMePXqgfv36uO222zBlyhQ88MADAFyHw507dw6SJOHbb79Fly5doNfr0aFDB5w8eRJ79uxB+/bt4ePjg3vuuQfXr193vs7IkSPRv39/TJ8+HSEhIfDz88NTTz1VKKzkZzQaMWnSJERERMDb2xsdO3bE1q1bC7ULDQ1FWFgY2rVrh4kTJyI+Ph7Hjx93adO7d2+EhYVh1qxZN/1M/u///g9Tp06F0WgsxSdYeXifICIiIiLyaNlmK1r8b50sr310Rh94aUr3K7WPjw98fHywevVq3H777aXu8Zk6dSree+891KtXD6NHj8ajjz4KX19fvP/++/Dy8sIjjzyC//3vf/j000+dz9m0aRN0Oh22bt2Kc+fOYdSoUQgKCsKbb75Z5GuMHz8eR48exYoVKxAeHo4ff/wRffv2xeHDh9G4ceNC7VNTU7FixQoAgEajcTmmVCoxc+ZMPProo5gwYQIiIyOLfW8TJ07E0qVL8eGHH2LSpEml+jwqA3uCiIiIiIjcQKVSYfHixViyZAn8/f3RqVMnvPzyy/jnn39KfN6kSZPQp08fNG/eHM888wz27duH1157DZ06dULbtm0xZswYbNmyxeU5Go0GCxcuRMuWLdGvXz/MmDEDH3zwAWw2W6HzX7hwAYsWLcJ3332HLl26ICYmBpMmTULnzp2xaNEil7aRkZHw8fGBv78/li9fjgceeADNmjUrdM6HHnoIbdq0wdSpU0t8b15eXpg6dSpmzZqF1NTUEttWJvYEVZaUC8CZzUDjuwG/cLmrISIiIqo19Goljs7oI9trl8WAAQPQr18/bN++HTt37sTatWvx1ltvYf78+Rg5cmSRz7nllluc63Xq1AEAxMbGuuxLSEhweU7r1q3h5eXl3L7jjjuQkZGB+Ph41K9f36Xt4cOHYbVa0aRJE5f9RqMRQUFBLvu2b98OLy8v7Ny5EzNnzsRnn31W7HudM2cOevbsedMenjFjxuCdd97BnDlzMHPmzBLbVhaGoMqy6j/Ahb+B+94D2o+SuxoiIiKiWkOSpFIPSasOdDod7rrrLtx111147bXXMHbsWEydOrXYEKRWq53rjhnWCu4rqoentDIyMqBUKrFv3z4ola6hzsfHx2W7QYMG8Pf3R9OmTZGQkIDBgwdj27ZtRZ63a9eu6NOnD6ZMmVLsewPsPWRvvvkmRo4cifHjx5f7fZQFh8NVlpie9sezW0puR0RERESUT4sWLZCZmVmp5zx06BCys7Od2zt37oSPjw+ioqIKtW3bti2sVisSEhLQqFEjlyUsLKzY1xg3bhyOHDmCH3/8sdg2s2fPxi+//IK///67xHoHDRqEli1bYvr06aV4dxXHEFRZnCFoK2CzltiUiIiIiGqfxMRE9OzZE0uXLsU///yDuLg4fPfdd3jrrbfw4IMPVuprmUwmjBkzBkePHsWaNWswdepUjB8/HgpF4V//mzRpgsceewzDhw/HqlWrEBcXh927d2PWrFn47bffin0NLy8vPPHEE5g6dWqxs+TFxsbisccewwcffHDTmmfPno2FCxdWeiAsCkNQZQlvC+gMQE4qcPmA3NUQERERUTXj4+ODjh074t1330XXrl3RqlUrvPbaa3jiiSfw0UcfVepr9erVC40bN0bXrl0xePBgPPDAA5g2bVqx7RctWoThw4fj+eefR9OmTdG/f3/s2bMH9erVK/F1xo8fj2PHjuG7774rts2MGTNKNVyvZ8+e6NmzJywWy03bVpQkyjK5eTWTlpYGg8GA1NRU+Pn5yV0OsHIYcOxnoMcrQLcX5a6GiIiIqMbJyclBXFwcGjRoAJ1OJ3c51dLIkSORkpLivN9QTVLS178s2YA9QZXJMSTuzGZ56yAiIiIiomIxBFWmmB72x/jdQE6avLUQEREREVGRPGcuQU8QEA0ExgBJZ4Bz24Fm/eSuiIiIiIhqmcWLF8tdQrXHnqDK5hwSx6myiYiIiIiqI4agysbrgoiIiIiIqjWGoMoW3RmQlPYhccnn5K6GiIiIiIgKYAiqbDo/IOo2+zqHxBERERERVTsMQVWBQ+KIiIiIiKothqCq4AhBcX8A1qq/4y0REREREZUeQ1BVCG8L6AxATipw+YDc1RARERERUT4MQVVBoQQadrevn+V1QUREREQEjBw5Ev379y/y2KFDh/DAAw8gNDQUOp0O0dHRGDx4MBISEjBt2jRIklTi4ji/JEl46qmnCp1/3LhxkCQJI0eOrMJ36DkYgqoKrwsiIiIiolK4fv06evXqhcDAQKxbtw7Hjh3DokWLEB4ejszMTEyaNAlXrlxxLpGRkZgxY4bLPoeoqCisWLEC2dnZzn05OTlYvnw56tWrJ8fbq5ZUchdQYzXsYX+M3w3kpNlnjSMiIiKiyicEYM6S57XVXkBuT0x57dixA6mpqZg/fz5UKvuv5w0aNECPHj2cbXx8fJzrSqUSvr6+CAsLK3Sudu3a4cyZM1i1ahUee+wxAMCqVatQr149NGjQoEJ11iQMQVUloD4QGGO/X9C57UCzfnJXRERERFQzmbOAmeHyvPbLlwGNd4VOERYWBovFgh9//BEDBw50Dm8rr9GjR2PRokXOELRw4UKMGjUKW7durdB5axIOh6tKHBJHRERERDdx++234+WXX8ajjz6K4OBg3HPPPZg7dy6uXbtWrvM9/vjj+PPPP3H+/HmcP38eO3bswOOPP17JVXs29gRVpZiewJ4vGYKIiIiIqpLay94jI9drV4I333wTzz33HDZv3oxdu3bhs88+w8yZM7Ft2zbExsaW6VwhISHo168fFi9eDCEE+vXrh+Dg4Eqps6ZgCKpK0Z0BhQpIOgsknwMCouWuiIiIiKjmkaQKD0mrDoKCgjBo0CAMGjQIM2fORNu2bfH2229jyZIlZT7X6NGjMX78eADAxx9/XNmlejwOh6tKOj8g8jb7+hlOlU1EREREpaPRaBATE4PMzMxyPb9v374wmUwwm83o06dPJVfn+dgTVNViegIX/rIPiWs/Su5qiIiIiEhGqampOHjwoMu+w4cPY926dRgyZAiaNGkCIQR++eUXrFmzBosWLSrX6yiVShw7dsy5Tq4YgqpaTA9gyxtA3B+A1QIo+ZETERER1VZbt25F27ZtXfb16NEDjRo1wvPPP4/4+HhotVo0btwY8+fPx7Bhw8r9Wn5+vEVLcSQhhJC7iPJKS0uDwWBAampq9f0i26zAWw2AnFRgzEYgqoPcFRERERF5rJycHMTFxaFBgwbQ6XRyl0NuVtLXvyzZgNcEVTWFEmjY3b7OWeKIiIiIiGTHEOQOvF8QEREREVG1wRDkDg172B8v7rEPiyMiIiIiItkwBLlDQH0gqBEgrMC5P+WuhoiIiIioVmMIchcOiSMiIiIiqhYYgtzFMSSOIYiIiIiISFYMQe4S3RlQqICks0BSnNzVEBERERHVWgxB7qLzAyJvs6+f3SJvLUREREREtRhDkDvxuiAiIiIiItkxBLmTIwSd3QZYLfLWQkRERERUSzEEuVN4G0DnDxhTgcsH5K6GiIiIiGRw9epVPPPMM2jUqBF0Oh3q1KmDTp064dNPP0VWVhYAIDo6GpIkQZIkeHl5ITY2FvPnz3c5z+LFi+Hv71/ka0iShNWrV1fxO/FcDEHupFACDbvb1zkkjoiIiKjWOXv2LNq2bYv169dj5syZOHDgAP7++2+8+OKL+PXXX7Fx40Zn2xkzZuDKlSs4cuQIHn/8cTzxxBNYu3atjNXXHCq5C6h1YnoAR1fbQ1D3yXJXQ0REROTxhBDItmTL8tp6lR6SJJW6/dNPPw2VSoW9e/fC29vbub9hw4Z48MEHIYRw7vP19UVYWBgAYPLkyXjrrbewYcMG3HPPPZX3BmophiB3c9wv6OIeICcV0BnkrYeIiIjIw2VbstFxeUdZXnvXo7vgpfYqVdvExERnD1D+AJRfUYHKZrPhxx9/RHJyMjQaTYXqJTsOh3O3gPpAUCNAWIG47XJXQ0RERERucvr0aQgh0LRpU5f9wcHB8PHxgY+PDyZPzhspNHnyZPj4+ECr1WLgwIEICAjA2LFj3V12jcSeIDnE9AQST9uHxDW/T+5qiIiIiDyaXqXHrkd3yfbaFbV7927YbDY89thjMBqNzv0vvPACRo4ciStXruCFF17A008/jUaNGlX49YghSB4xPYHdX3ByBCIiIqJKIElSqYekyalRo0aQJAknTpxw2d+wYUMAgF7vGqiCg4PRqFEjNGrUCN999x1iY2PRvn17tGjRAgDg5+eHzMxM2Gw2KBR5A7xSUlIAAAYDL7soDofDySG6M6BQAclxQFKc3NUQERERkRsEBQXhrrvuwkcffYTMzMwyPTcqKgqDBw/GlClTnPuaNm0Ki8WCgwcPurTdv38/AKBJkyYVrrmmYgiSg9YXiMq9eO/sFnlrISIiIiK3+eSTT2CxWNC+fXusXLkSx44dw4kTJ7B06VIcP34cSqWy2Oc+88wz+OWXX7B3714AQMuWLXH33Xdj9OjR2LRpE+Li4vD777/j6aefxuDBgxEREeGut+VxGILk4pgljkPiiIiIiGqNmJgYHDhwAL1798aUKVPQunVrtG/fHh9++CEmTZqE119/vdjntmjRAnfffTf+97//OfetXLkS3bp1w5NPPomWLVtiwoQJePDBBwvdWJVcSSL/ZOQeJi0tDQaDAampqfDz85O7nLK5uA+Y3xPQGoAXzwJKXp5FREREdDM5OTmIi4tDgwYNoNPp5C6H3Kykr39ZsgF7guQS3gbQ+QPGVODyfrmrISIiIiKqNRiC5KJQAg2729c5JI6IiIiIyG0YguQU09P+yBBEREREROQ2DEFyismdHOHiXiAnVd5aiIiIiIhqCYYgOfnXA4IaAcIKxG2XuxoiIiIij+HBc3tRBVTW150hSG4cEkdERERUamq1GgCQlZUlcyUkB8fX3fF9UF6yzststVoxbdo0LF26FFevXkV4eDhGjhyJV199FZIkyVma+8T0BHZ/wRBEREREVApKpRL+/v5ISEgAAHh5edWe3xtrMSEEsrKykJCQAH9//xJvKlsasoagOXPm4NNPP8WSJUvQsmVL7N27F6NGjYLBYMCECRPkLM19ojsDChWQHAcknQUCG8pdEREREVG1FhYWBgDOIES1h7+/v/PrXxGyhqC//voLDz74IPr16wcAiI6OxjfffIPdu3fLWZZ7aX2BqI7A+R3AmS0MQUREREQ3IUkS6tati9DQUJjNZrnLITdRq9UV7gFykDUE3Xnnnfjiiy9w8uRJNGnSBIcOHcKff/6JefPmFdneaDTCaDQ6t9PS0txVatWK6ZEbgjYDHcbIXQ0RERGRR1AqlZX2SzHVLrJOjPDSSy9hyJAhaNasGdRqNdq2bYuJEyfiscceK7L9rFmzYDAYnEtUVJSbK64ijskR4rYDVou8tRARERER1XCyhqBvv/0Wy5Ytw/Lly7F//34sWbIEb7/9NpYsWVJk+ylTpiA1NdW5xMfHu7niKlK3DaDzB4ypwOX9cldDRERERFSjyToc7oUXXnD2BgFAbGwszp8/j1mzZmHEiBGF2mu1Wmi1WneXWfUUSqBhd+DoavuQuKjb5K6IiIiIiKjGkrUnKCsrCwqFawlKpRI2m02mimTE+wUREREREbmFrD1B999/P958803Uq1cPLVu2xIEDBzBv3jyMHj1azrLkEdPD/nhxL5CdAuj95ayGiIiIiKjGkjUEffjhh3jttdfw9NNPIyEhAeHh4XjyySfxv//9T86y5OFfDwhqDCSeAs5tB5rfL3dFREREREQ1kiSEEHIXUV5paWkwGAxITU2Fn5+f3OVU3JoXgd2fA+1HA/e9K3c1REREREQeoyzZQNZrgqgA53VBW+Stg4iIiIioBmMIqk6iOwEKFZAcBySdlbsaIiIiIqIaiSGoOtH6AlEd7evsDSIiIiIiqhIMQdWNY5Y4TpVNRERERFQlGIKqG8d1QXHbAKtF3lqIiIiIiGoghqDqpm4bQB8AGNOAS/vkroaIiIiIqMZhCKpuFEqgYXf7OofEERERERFVOoag6sgxJO4sJ0cgIiIiIqpsDEHVUcPcyREu7gWyU2QthYiIiIiopmEIqo78o4CgxoCwAue2y10NEREREVGNwhBUXTmGxPG6ICIiIiKiSsUQVF0xBBERERERVQmGoOoqujOgUAPJ54Cks3JXQ0RERERUYzAEVVdaHyCqo32dvUFERERERJWGIag6i8mdJe4Mp8omIiIiIqosDEHVmSMExW0DrBZ5ayEiIiIiqiEYgqqzum0AfQBgTAMu7ZO7GiIiIiKiGoEhqDpTKIGG3e3rvC6IiIiIiKhSMARVd5wqm4iIiIioUjEEVXcNc68LurQXyE6RtRQiIiIiopqAIai6848CgpsAwmafIIGIiIiIiCqEIcgTcEgcEREREVGlYQjyBI4hcWd5vyAiIiIioopiCPIE0Z0BhRpIPgcknZW7GiIiIiIij8YQ5Am0PkBUR/s6h8QREREREVUIQ5CniMkdEneGQ+KIiIiIiCqCIchTOCZHiNsGWM3y1kJERERE5MEYgjxF3daAPhAwpgGX9sldDRERERGRx2II8hQKJdCwu32d1wUREREREZUbQ5An4XVBREREREQVxhDkSRz3C7q0F8hOkbUUIiIiIiJPxRDkSfyjgOAmgLDZJ0ggIiIiIqIyYwjyNI5Z4nhdEBERERFRuTAEeRpnCNoECCFvLUREREREHoghyNPU7wQo1EDKBSDprNzVEBERERF5HIYgT6P1Aerdbl/nkDgiIiIiojJjCPJEjvsFnd0qZxVERERERB6JIcgTOa4LitsGWM3y1kJERERE5GEYgjxR3daAPhAwpgGX9sldDRERERGRR2EI8kQKZd6QOF4XRERERERUJgxBnor3CyIiIiIiKheGIE8V08P+eGkfkJ0sby1ERERERB6EIchTGSKB4CaAsNknSCAiIiIiolJhCPJkziFxW+Stg4iIiIjIgzAEeTJnCNoECCFvLUREREREHoIhyJPV7wQo1EDKBSDprNzVEBERERF5BIYgT6b1Aerdbl/nLHFERERERKXCEOTpHLPE8bogIiIiIqJSYQjydI7rguK2AVazvLUQEREREXkAhiBPF9Ya0AcCpnTg4l65qyEiIiIiqvYYgjydQgE07G5fP8shcUREREREN8MQVBM4p8rm5AhERERERDfDEFQTOCZHuLQPyE6WtxYiIiIiomqOIagmMEQCwU0BYbNPkEBERERERMViCKopOCSOiIiIiKhUGIJqCkcIOr0ZEELeWoiIiIiIqjGGoJoiuhOgUAOpF4Cks3JXQ0RERERUbTEE1RQab6De7fZ1DokjIiIiIioWQ1BN4pgl7gzvF0REREREVByGoJrEcV1Q3DbAapa3FiIiIiKiaoohqCYJaw3oAwFTOnBxr9zVEBERERFVSwxBNYlCkW9IHK8LIiIiIiIqCkNQTcP7BRERERERlYghqKZpmNsTdHk/kJ0sby1ERERERNUQQ1BNY4gAgpsCwmafIIGIiIiIiFwwBNVEHBJHRERERFQshqCayBGCTm8GhJC3FiIiIiKiaoYhqCaK7gQo1EDqBSDprNzVEBERERFVKwxBNZHGG6h3u32dQ+KIiIiIiFwwBNVUvC6IiIiIiKhIDEE1leOmqXHbAatZ3lqIiIiIiKoRhqCaKqw1oA8ETOnAxb1yV0NEREREVG0wBNVUCkVeb9C/q+SthYiIiIioGmEIqsnaDrM/7v8KSL8mby1ERERERNUEQ1BN1rA7EHkbYMkB/vpA7mqIiIiIiKoFhqCaTJKAbi/a1/cuBDJvyFsPEREREVE1wBBU0zXqDYS3BcxZwN8fyV0NEREREZHsGIJqOkkCuk22r+/+EshKkrceIiIiIiKZMQTVBk36AmGxgCkD2PmJ3NUQEREREcmKIag2kCSga+61Qbs+B7JTZC2HiIiIiEhODEG1RbP7gNAWgDHNHoSIiIiIiGophqDaQqEAuk6yr+/8GMhJk7ceIiIiIiKZMATVJi36A8FNgJxUYM+XcldDRERERCQLhqDaRKEEur5gX//rI8CYIW89REREREQykDUERUdHQ5KkQsu4cePkLKtma/kwENgQyE4C9i6QuxoiIiIiIreTNQTt2bMHV65ccS4bNmwAAAwaNEjOsmo2pQrokntt0F8fAqYseeshIiIiInIzWUNQSEgIwsLCnMuvv/6KmJgYdOvWTc6yar5bHgH86wOZ14F9i+WuhoiIiIjIrarNNUEmkwlLly7F6NGjIUlSkW2MRiPS0tJcFioHpRro8px9fcf7gDlH3nqIiIiIiNyo2oSg1atXIyUlBSNHjiy2zaxZs2AwGJxLVFSU+wqsaVo/CvhFAhlXgQNfy10NEREREZHbSEIIIXcRANCnTx9oNBr88ssvxbYxGo0wGo3O7bS0NERFRSE1NRV+fn7uKLNm2TMf+O15wC8CmHAAUGnlroiIiIiIqFzS0tJgMBhKlQ2qRU/Q+fPnsXHjRowdO7bEdlqtFn5+fi4LVUCbxwHfukDaJeDgMrmrISIiIiJyi2oRghYtWoTQ0FD069dP7lJqF7UO6DTRvr79XcBqlrUcIiIiIiJ3kD0E2Ww2LFq0CCNGjIBKpZK7nNrn1hGAdyiQegE4tELuaoiIiIiIqpzsIWjjxo24cOECRo8eLXcptZNaD3R6xr6+/W3AapG3HiIiIiKiKiZ7CLr77rshhECTJk3kLqX2aj8K8AoCks8BR76XuxoiIiIioiolewiiakDjDdz5f/b1bXMBm1XeeoiIiIiIqhBDENl1GAvoA4DE08C/P8pdDRERERFRlWEIIjutL3D7OPv6trmAzSZvPUREREREVYQhiPJ0/A+gNQDXjwPHfpa7GiIiIiKiKsEQRHl0BuD2/9rX2RtERERERDUUQxC5uv0pQOMLXDsCnFgjdzVERERERJWOIYhc6QPsw+IAYNtbgBDy1kNEREREVMkYgqiw28cBam/gyiHg1Hq5qyEiIiIiqlQMQVSYdxDQYYx9/Y857A0iIiIiohqFIYiKduf/ASo9cGkfcGaz3NUQEREREVUahiAqmk8o0H60fZ29QURERERUgzAEUfE6TQCUWiB+FxC3Te5qiIiIiIgqBUMQFc83DLh1hH1921x5ayEiIiIiqiQMQVSyThMBpQY4tx04t0PuaoiIiIiIKowhiEpmiADaPGZf3/aWvLUQEREREVUChiC6uc7PAgoVcHYrEL9b7mqIiIiIiCqEIYhuLqA+0Hqoff0P9gYRERERkWdjCKLS6fIcICmB0xvs9w4iIiIiIvJQDEFUOoENgVsesa9ve1veWoiIiIiIKoAhiEqvy/OApABOrAGuHJK7GiIiIiKicmEIotILbgy0GmBf532DiIiIiMhDlSsELVq0CFlZWZVdC3mCLpMASMCxX4BrR+WuhoiIiIiozMoVgl566SWEhYVhzJgx+Ouvvyq7JqrOQpsBLR60r7M3iIiIiIg8ULlC0KVLl7BkyRLcuHED3bt3R7NmzTBnzhxcvXq1suuj6qjrC/bHf38Erp+QtxYiIiIiojIqVwhSqVR46KGH8NNPPyE+Ph5PPPEEli1bhnr16uGBBx7ATz/9BJvNVtm1UnUR1gpodh8AAWx/R+5qiIiIiIjKpMITI9SpUwedO3fGHXfcAYVCgcOHD2PEiBGIiYnB1q1bK6FEqpYcvUGHvwMSz8hbCxERERFRGZQ7BF27dg1vv/02WrZsie7duyMtLQ2//vor4uLicOnSJTzyyCMYMWJEZdZK1Ul4G6BJX0DY2BtERERERB5FEkKIsj7p/vvvx7p169CkSROMHTsWw4cPR2BgoEubhIQEhIWFVemwuLS0NBgMBqSmpsLPz6/KXoeKcXEfML8nICmBCfuBgGi5KyIiIiKiWqos2UBVnhcIDQ3FH3/8gTvuuKPYNiEhIYiLiyvP6clTRN4KxPQCzmwCts8DHvhA7oqIiIiIiG6qXMPhunXrhnbt2hXabzKZ8NVXXwEAJElC/fr1K1YdVX/dJtsfDy4HUuLlrYWIiIiIqBTKFYJGjRqF1NTUQvvT09MxatSoChdFHqReR6BBV8BmBna8J3c1REREREQ3Va4QJISAJEmF9l+8eBEGg6HCRZGHcfQG7f8KSLssby1ERERERDdRpmuC2rZtC0mSIEkSevXqBZUq7+lWqxVxcXHo27dvpRdJ1Vx0Z6B+J+D8DmDH+8A9c+SuiIiIiIioWGUKQf379wcAHDx4EH369IGPj4/zmEajQXR0NAYMGFCpBZKH6PoC8PUOYN9ioPNzgG8duSsiIiIiIipSmULQ1KlTAQDR0dEYPHgwdDpdlRRFHqhhdyDyNuDibuCvD4A+b8pdERERERFRkcp1TdCIESMYgMiVJOVdG7R3IZBxXd56iIiIiIiKUeoQFBgYiBs3bgAAAgICEBgYWOxCtVSjXkB4W8CcBfz9kdzVEBEREREVqdTD4d599134+vo614uaHY5qOUdv0DdDgD3zgU7PAF4MxURERERUvUhCCCF3EeWVlpYGg8GA1NRU+Pn5yV0OAYAQwOddgKuH7ZMl9HxV7oqIiIiIqBYoSzYo1zVBixcvLnK/xWLBlClTynNKqinyXxu063MgO0XWcoiIiIiICipXCJowYQIGDRqE5ORk574TJ06gY8eO+OabbyqtOPJQTfsBoS0AY5o9CBERERERVSPlCkEHDhzAxYsXERsbiw0bNuDjjz9Gu3bt0KxZMxw6dKiyayRPo1DYh8IBwM6PgZw0eeshIiIiIsqnTPcJcoiJicGOHTswceJE9O3bF0qlEkuWLMHQoUMruz7yVC0eBIKbAjdOALu/ALpOkrsiIiIiIiIA5ewJAoDffvsNK1aswB133AF/f38sWLAAly9frszayJMplHnB5++PAWOGvPUQEREREeUqVwh68sknMWjQIEyePBnbt2/HP//8A41Gg9jYWHz77beVXSN5qpYPA4ExQHYSsHeB3NUQEREREQEoZwjasWMHdu3aheeffx6SJCEsLAxr1qzBjBkzMHr06MqukTyVUpXXG/TXh4ApS956iIiIiIhQzhC0b98+tG7dutD+cePGYd++fRUuimqQ2EGAf30g8zqwb7Hc1RARERERlS8EabVanDlzBq+++iqGDh2KhIQEAMDatWthsVgqtUDycEo10OV5+/qO9wBztqzlEBERERGVKwT98ccfiI2Nxa5du7Bq1SpkZNgvej906BCmTp1aqQVSDdB6KGCIAjKuAfu/lrsaIiIiIqrlyhWCXnrpJbzxxhvYsGEDNBqNc3/Pnj2xc+fOSiuOagiVBug80b6+4z3AYpSzGiIiIiKq5coVgg4fPoyHHnqo0P7Q0FDcuHGjwkVRDdR2GOAbDqRdAg4uk7saIiIiIqrFyhWC/P39ceXKlUL7Dxw4gIiIiAoXRTWQSpvXG7T9XcBqlrUcIiIiIqq9yhWChgwZgsmTJ+Pq1auQJAk2mw07duzApEmTMHz48MqukWqKdsMB71Ag9QJniiMiIiIi2ZQrBM2cORPNmjVDVFQUMjIy0KJFC3Tt2hV33nknXn311cqukWoKtT5vprh1rwCX9stbDxERERHVSpIQQpT3yRcuXMCRI0eQkZGBtm3bonHjxpVZ202lpaXBYDAgNTUVfn5+bn1tKiebDVgxFDj5u/0aof9sBXzryF0VEREREXm4smSDCoUguTEEeaicVGB+b+DGSSDqdmDEL/YZ5IiIiIiIyqks2UBV2pM+99xzpS5g3rx5pW5LtZDOAAz5BviyJxC/E1gzCbj/fUCS5K6MiIiIiGqBUoegAwcOlKqdxF9kqTSCGwEDFwDLBgH7lwB1bwE6jJW7KiIiIiKqBTgcjuT157vAxmmAQgUM/xmI7iR3RURERETkgcqSDco1O1x+8fHxiI+Pr+hpqLbqNBFoNQCwWYBvhwMp/F4iIiIioqpVrhBksVjw2muvwWAwIDo6GtHR0TAYDHj11VdhNvMmmFQGkgQ88BEQdguQdQNY8ShgypK7KiIiIiKqwcoVgv7v//4PX3zxBd566y0cOHAABw4cwFtvvYUFCxZgwoQJlV0j1XQaL2DIcsArGLj6D/DzeMBzR2kSERERUTVXrmuCDAYDVqxYgXvuucdl/5o1azB06FCkpqZWWoEl4TVBNcy5HcBXD9iHxvWeDnSeKHdFREREROQhqvyaIK1Wi+jo6EL7GzRoAI2G93uhcoruBPSdbV/fOA04tVHWcoiIiIioZipXCBo/fjxef/11GI1G5z6j0Yg333wT48ePr7TiqBbqMBZoNwKAAL4fDdw4LXdFRERERFTDlGs43EMPPYRNmzZBq9WidevWAIBDhw7BZDKhV69eLm1XrVpVOZUWgcPhaiiLCVhyHxC/CwhuAozdBOj49SUiIiKi4pUlG5T6Zqn5+fv7Y8CAAS77oqKiynMqosJUGuCRr4EvugM3TgKr/mOfOEFR4RndiYiIiIjK3hMkhEB8fDxCQkKg1+urqq5SYU9QDXdpP7CwL2A1Al1fAHq+KndFRERERFRNVenECEIINGrUCBcvXix3gUSlEtEOeOAD+/q2ucC/q2Uth4iIiIhqhjKHIIVCgcaNGyMxMbEq6iFy1XoIcEfuZBur/wtcPSJvPURERETk8cp1kcXs2bPxwgsv4MgR/kJKbtB7OtCwB2DOAlYMBTIZwImIiIio/Mo1O1xAQACysrJgsVig0WgKXRuUlJRUaQWWhNcE1SJZScCXPYDkc0CDrsDjPwLKcs3rQUREREQ1UJXPDvfee++V52lE5ecVCAz5BpjfG4jbBqx/FbhnttxVEREREZEHKldPUHXBnqBa6NgvwMrH7esPfgy0fVzeeoiIiIioWqjS2eEczpw5g1dffRVDhw5FQkICAGDt2rX4999/y3tKoptrfj/Q7SX7+q/PAhf3ylsPEREREXmccoWgP/74A7Gxsdi1axdWrVqFjIwMAMChQ4cwderUSi2QqJBuk4Fm9wFWE7DiMSDtitwVEREREZEHKVcIeumll/DGG29gw4YN0Gg0zv09e/bEzp07K604oiIpFMBDnwEhzYGMq8C3wwCLUe6qiIiIiMhDlCsEHT58GA899FCh/aGhobhx40aFiyK6Ka0vMHQ5oPMHLu4Bfn0O8NzL24iIiIjIjcoVgvz9/XHlSuEhSAcOHEBERESFiyIqlcCGwKBFgKQADi4Fdn8hd0VERERE5AHKFYKGDBmCyZMn4+rVq5AkCTabDTt27MCkSZMwfPjwyq6RqHgxPYG7Xrev/z7FPn02EREREVEJyhWCZs6ciebNm6NevXrIyMhAixYt0LVrV9x555149dVXK7tGopLdMQ64ZTAgrMC3I+w3VCUiIiIiKkaZbpZqs9kwd+5c/PzzzzCZTBg2bBgGDBiAjIwMtG3bFo0bN66qOomKJ0nA/e8DN04Clw/YZ4wbsx7QeMtdGRERERFVQ2XqCXrzzTfx8ssvw8fHBxEREVi+fDm+//57PPLIIwxAJC+1Hhi8DPAOBa4dAVY/zYkSiIiIiKhIZQpBX331FT755BOsW7cOq1evxi+//IJly5bBZrNVVX1EpWeIAAZ/DSjUwNHVwPZ35K6IiIiIiKqhMoWgCxcu4N5773Vu9+7dG5Ik4fLly+Uu4NKlS3j88ccRFBQEvV6P2NhY7N27t9zno1qu3u1Av7ft65vfAE78Lm89RERERFTtlCkEWSwW6HQ6l31qtRpms7lcL56cnIxOnTpBrVZj7dq1OHr0KN555x0EBASU63xEAIBbRwLtxwAQwA9jgesn5a6IiIiIiKqRMk2MIITAyJEjodVqnftycnLw1FNPwds77yL0VatWlep8c+bMQVRUFBYtWuTc16BBg7KURFS0vrOB68eB8zuAFUOBsZsAvb/cVRERERFRNVCmnqARI0YgNDQUBoPBuTz++OMIDw932VdaP//8M9q3b49BgwYhNDQUbdu2xZdffllse6PRiLS0NJeFqEgqDTBoCeAXCSSeBlY9AdiscldFRERERNWAJIR8U2g5htY999xzGDRoEPbs2YNnnnkGn332GUaMGFGo/bRp0zB9+vRC+1NTU+Hn51fl9ZIHunwQWNgXsGQDnZ8Fek+TuyIiIiIiqgJpaWkwGAylygayhiCNRoP27dvjr7/+cu6bMGEC9uzZg7///rtQe6PRCKPR6NxOS0tDVFQUQxCV7PD3wA9j7OsDFwKtBshbDxERERFVurKEoDINh6tsdevWRYsWLVz2NW/eHBcuXCiyvVarhZ+fn8tCdFOxA4FOz9jXV48DrhyStx4iIiIikpWsIahTp044ceKEy76TJ0+ifv36MlVENVavqUCj3vZhcSseAzJvyF0REREREclE1hD07LPPYufOnZg5cyZOnz6N5cuX44svvsC4cePkLItqIoUSGLAACIwBUuOBb4cD1vJN7U5EREREnk3WENShQwf8+OOP+Oabb9CqVSu8/vrreO+99/DYY4/JWRbVVHp/YOg3gMbXPnX271PkroiIiIiIZCDrxAgVVZaLn4icTqwFvhkKQAD3fwDcWngmQiIiIiLyLB4zMQKRLJreA/R8xb7+2/PAhV3y1kNEREREbsUQRLVTl0lAiwcBmxlY+TiQeknuioiIiIjITRiCqHaSJODBT4A6rYDMBHsQMufIXRURERERuQFDENVeWh9gyDJAHwhc3g8sfwTIuC53VURERERUxRiCqHYLiAYeWQKo9EDcH8BnnYFzf8pdFRERERFVIYYgogZdgf9sAYKbAhlXgSX3A9veBmw2uSsjIiIioirAEFSJ/k38Fx4843jtFtoceGIzcMsQQNiAza8DywYCmTfkroyIiIiIKhlDUCUQQmDC5gkY8usQbLu4Te5yqLy0PsBDnwEPfASodMCZTfbhcef/krsyIiIiIqpEDEGVQJIkRBuiAQBfHv6SvUGeTJKAdsPsvULBTYD0K8Di+4Dt8zg8joiIiKiGYAiqJMNbDIdGocGh64ew99peucuhiqrTEnhiCxD7CCCswKbp9tnjMhPlroyIiIiIKoghqJIE64PxUOOHAADzD8+XuRqqFFof4OEvgAc+tA+PO73BPjzuwk65KyMiIiKiCmAIqkQjW46EUlLir8t/4d/Ef+UuhyqDJAHthgNjNwFBjYD0y8Cie4E/3+PwOCIiIiIPxRBUiSJ9I9G3QV8AwILDC2SuhipVWCvgP1uBVgPtw+M2TgW+GQJkJcldGRERERGVEUNQJRvTagwAYOP5jTibelbmaqhSaX2BAfOB+94DlFrg1Lrc4XG75K6MiIiIiMqAIaiSNQ5ojO5R3SEgsPDwQrnLocomSUD7UcATm4DAGCDtErD4XmDHBwBnBSQiIiLyCAxBVWBs7FgAwG9nf8OVjCsyV0NVIiwWePIPoNUAwGYBNrwGfDOUw+OIiIiIPABDUBVoHdIat4XdBouwYMnRJXKXQ1VF6wsMWAD0m2cfHndyLfB5VyB+j9yVEREREVEJGIKqiKM36IeTPyAph70DNZYkAR3GAGM3AIENgdR4YFFf4K+PODyOiIiIqJpiCKoit9e9HS2DWiLHmoOlR5fKXQ5Vtbqtgf/8AbTobx8et/4VYMWjQHay3JURERERUQEMQVVEkiQ8EfsEAGDF8RXIMGXIXBFVOZ0fMGgx0O8dQKkBTqwBPusKXNwnd2VERERElA9DUBXqUa8HGhoaIt2cjpUnVspdDrmDJAEdxgJjNgAB0UDqBWBhH+DvTzg8joiIiKiaYAiqQgpJgTGx9vsGfXX0K+RYcmSuiNwmvA3w5DagxYOAzQysmwKsfJzD44iIiIiqAYagKnZPg3sQ7h2OpJwkrD69Wu5yyJ10BmDQEuCeufbhccd/tc8ed4nD44iIiIjkxBBUxdQKNUa0HAEAWHRkEcw2s8wVkVtJEtDxP8DodYB/fSDlArCgD7DzMw6PIyIiIpIJQ5AbPNz4YQTqAnE58zJ+j/td7nJIDhHt7MPjmt9vHx73+2Tg22FAdorclRERERHVOgxBbqBT6TCsxTAAwILDC2ATNpkrIlno/YFHvgbueQtQqIFjv+QOj9svd2VEREREtQpDkJsMbjoYPmofnEk9gy3xW+Quh+QiSUDHJ4Ex6wD/ekDKefvscbu+4PA4IiIiIjdhCHITX40vhjQbAsDeGyT4C2/tFnEr8OR2oNl9gNUErH0B+G4EkJMqd2VERERENR5DkBs93vxxaJVaHL5xGLuu7pK7HJKb3h8YvBToO9s+PO7oT8Dn3YDLB+WujIiIiKhGYwhyoyB9EB5u/DAAYP7h+TJXQ9WCJAG3/9c+e5yhHpAcByy4C9j9JYfHEREREVURhqBKdOxK2k3bjGw5EipJhV1XduHw9cNuqIo8QuStwJN/AE3vtQ+PWzMJ+H4Uh8cRERERVQGGoEoghMD/fXMA97y/HX+cvF5i23CfcNzb8F4A7A2iArwCgSHLgbvfBBQq4N8fgffbAH++B5gy5a6OiIiIqMZgCKoEkiQh1FcLAJi15histpKHMY1pNQYSJGyO34zTyafdUSJ5CkkC7hwPjPodCGoEZCcBG6cC77cG/voIMGXJXSERERGRx2MIqiT/17MR/HQqHL+ajh/2XSyxbUP/huhVrxcAYOGRhe4ojzxNVAfg6V1A/8+AgGgg8zqw/hXggzbAzs8Ac47cFRIRERF5LIagSuLvpcGEXo0BAO9sOIEsk6XE9mNjxwIA1sStwaWMS1VeH3kgpQpoMxQYvxd44CP7fYUyrgG/TwY+aGufPMFilLtKIiIiIo/DEFSJht1RH1GBelxLM2L+9rgS27YMbok76t4Bq7Bi0ZFFbqqQPJJSDbQbBozfB9z3HuAXCaRftk+e8EE7YO8iwGKSu0oiIiIij8EQVIm0KiVe7NMMAPDZH2eQkF7ykCVHb9CPp37EjewbVV4feTiVBmg/CpiwH7j3bcC3LpB2Efh1IvDRrcD+rwFryT2QRERERMQQVOnuu6Uu2kT5I8tkxbsbTpXYtkNYB9wScgtMNhO+Pvq1myokj6fSArc9AUw4CPSdA3iHAikXgJ/HAx+1Bw5+wzBEREREVAKGoEomSRJe6dccALByzwWcupZeYtuxrey9QStPrESa6eb3GSJyUuuA258Cnjlkn1bbK9h+s9XVTwGfdAT++Q6wWeWukoiIiKjaYQiqAh2iA9G3ZRhsApi19niJbbtFdUMj/0bINGdixfEVbqqQahSNl31a7Yn/AL2nA/pAIPE0sGos8MkdwJFVgM0md5VERERE1QZDUBWZfE8zqBQSNh9PwI7TxV/vo5AUGBM7BgCw9OhSZFuy3VUi1TQab6DzRHsY6vkaoPMHbpwAvh8FfNYJOPozwxARERERGIKqTINgbzx+e30AwMw1x2Ar4QaqfaP7IsInAsnGZKw6tcpdJVJNpfUFuk6yh6HuLwNaA5BwFPh2GPBFV+D4GkCUfENfIiIiopqMIagKTejVGL5aFf69nIbVB4u/F5BKocLoVqMBAIv/XQyz1eyuEqkm0xmA7pOBiYeAri8CGl/g6mFgxVDgyx7AyfUMQ0RERFQrMQRVoUBvDZ7u0QgAMHfdCeSYi79I/cFGDyJYH4yrmVfxW9xv7iqRagN9ANDzFXvPUOfnALU3cPkAsHwQML83cHoTwxARERHVKgxBVWxUp2hE+OtxJTUHC/4s/gaqWqUWw1sMBwAsOLwAVs7qRZXNKxDoPdUehu6cAKj0wKW9wNKHgYV9gbN/yF0hERERkVswBFUxnVqJF/o0BQB8uvUMEjOMxbZ9pOkj8NX44lzaOWyO3+yuEqm28Q4G7n7dHoZuHweodED8TuCrB4DF9wHndshdIREREVGVYghygwdahyM2woAMowXvbyr+Bqream882uxRAMCX/3wJwSFKVJV8QoG+M+03Xb3tSUCpAc5tBxbfCyx5ALiwS+4KiYiIiKoEQ5AbKBQSXr7XfgPVZbsu4Mz1jGLbPtb8MehVehxLOoa/L//trhKpNvOrC9z7lj0MtR8DKNRA3B/AwruBrx8GLu6Vu0IiIiKiSsUQ5CZ3xAShd/NQWG0Cs0u4gWqALgADGg8AAHx5+Et3lUcEGCKA++YBE/YD7UYAChVwZhMwvxew7BH7ZApERERENQBDkBu9dE8zKBUSNhy9hl1nE4ttN6LlCKgUKuy9thcHEw66r0AiAPCvBzzwATB+L9DmcUBSAqfWAV90B7551D5MjkM1iYiIyIMxBLlRo1BfDL0tCkDJN1AN8w7DAzEPAADmH57vtvqIXAQ2APp/DIzfA9wyBJAUwInf7MPkPmwHbJ0NJJ2Vu0oiIiKiMmMIcrNnejWBt0aJQxdT8cs/l4ttN6rlKEiQ8MfFP3Ay+aQbKyQqICgGePhzYNxuoM1j9vsMJZ0Fts4CPmgLzL8L2DMfyEqSu1IiIiKiUmEIcrMQXy3+2z0GAPDW78XfQDXaEI27o+8GYL9vEJHsghsD/T8BXjgFPPwlENPL3jt0cTfw2/PA202AFY8BR38GLMVPBU9EREQkN4YgGYzp3BBhfjpcSsnGV3+fK75dqzEAgN/P/Y74tHg3VUd0Expv4JZHgGGrgOeOAXe/CYTFAjYzcPxX4Nth9kD0y0Tg/N+8foiIiIiqHYYgGeg1SkzKvYHqh5tPIznTVGS75kHN0SmiE2zChkX/LnJniUSl4xsG3DkeeOpP4L9/A52eAXzDgZwUYN8iYFFf4P3WwOY3gcQzcldLREREBIAhSDYPtY1A87p+SM+x4IPNxd9A9YnYJwAAq0+vRkJWgrvKIyq7Oi2Au2YAzx4Bhv9kv35I4wOknAe2vWWfTOHLXsDuL4HM4mdHJCIiIqpqDEEyUSokvJJ7A9WlO8/j3I3MItvdWudWtA1tC7PNjK+Pfu3OEonKR6EEGna3Xz806RQwYAHQ6C77VNuX9gJrJgHvNAGWDwH+/REw58hdMREREdUyDEEy6tw4GN2bhsBsFXhrXfE3UB0bOxYAsPLESqQaU91VHlHFabyA2IHA498Dzx8H+swC6rYGbBbg5Frgu5H264d+/j/g3A7AZpO7YiIiIqoFGIJkNuWe5lBIwJrDV7HvfNFTDHeJ6IKmAU2RbcnG8uPL3VwhUSXxCQXueBp4chvw9C6g87OAXyRgTAX2fwUsvtd+/dCm14EbxQ8RJSIiIqoohiCZNQ3zxSPt7TdQffO3YxBFzKQlSZKzN2jZsWXIMme5tUaiShfaDOg9DZh4GBjxC9DmcUDjC6ReALa/DXzUHviiO7DzMyDjutzVEhERUQ3DEFQNPHdXE+jVSuy/kIK1R64W2eau+nehnm89pBpT8f3J791cIVEVUSiABl2B/h/b7z80cCHQuI/9+qHLB4DfJwPvNAWWPQIc+QEwZ8tdMREREdUADEHVQKifDk92awgAmL32OEyWwtdFKBVKjG41GgCw5OgSmKxFT6tN5LHUeqDVAOCxb4HnTwB95wDhbQFhBU6tA74fbb9+6KdxQNx2Xj9ERERE5cYQVE080aUhQny1uJCUha93ni+yzf0x9yNUH4qErAT8cuYXN1dI5EY+IcDtTwH/2QqM2wN0eR4wRAHGNODAUmDJfcB7scDGaUBC8ZOKEBERERWFIaia8Naq8PxdTQAAH2w6hdQsc6E2GqUGI1qOAAAsPLIQVpvVrTUSySKkCdDrf8Az/wAj1wDthgNaA5B2EfjzXeCTjsCH7e0zzB38Bkg+BxRxbR0RERGRgySKuhLfQ6SlpcFgMCA1NRV+fn5yl1NhVpvAve9vx4lr6fhP14Z4Ofc+QvllmbNw9w93I9WYirld56Jvg74yVEokM3OOfYrtQyuB0xvsU27n5xsO1L8DqHcHUP9OIKS5/fojIiIiqrHKkg0YgqqZrScSMHLRHmiUCmx6vhuiAr0Ktfn04Kf45NAnaBrQFN/d/x0kSZKhUqJqIisJuLATuPAXcP5v4MrBwqFI5w/Uuz0vFNVtA6g0MhRLREREVYUhyIMJITBswW78efoG7m8djg+Hti3UJtWYiru+vwvZlmx83OtjdI3sKkOlRNWUKRO4uBe48Ddw/i/g4h6g4LTyKj0Q2T43FN0BRN4GaH3kqZeIiIgqBUOQh/v3ciru+/BPCAGsHtcJbaL8C7V5e8/bWHJ0CdqFtsOSe5a4v0giT2E1A1f+yespuvA3kF3gxsSSEqh7C1DvzrxhdN7B8tRLRERE5cIQVANM+u4Qvt93EbdFB2Llk7cXGvKWkJWAvj/0hdlmxuK+i3FrnVtlqpTIw9hswI2TrqEoNb5wu+AmecPn6t0B+NcDOPSUiIio2mIIqgGupGajx9tbkWO24fNht6JPy7BCbab/PR3fn/wenSM649Pen8pQJVENkRLvel3R9WOF2/hF5A2fq3cnENKMky0QERFVIwxBNcTb607goy2n0SDYG+uf7Qq10vUXrvi0eNy3+j7YhA3f3f8dmgU2k6lSohqmNJMt6AOAqNvzQlHd1pxsgYiISEYMQTVEhtGC7nO34EaGCTMebInhd0QXavPithexNm4t+kT3wdvd3nZ/kUS1QVkmW3AMn4vswMkWiIiI3IghqAZZuvM8Xl19BIHeGmx9oTv8dGqX4yeSTmDgLwMhQcLP/X9GtCFankKJapPSTLYACQhpCoS3AyLa2R/DWgEqrSwlExER1XQMQTWIxWpDn/e24cz1TPy3ewwm9y085G38pvH44+IfeLjxw5h+53QZqiSq5fJPtnBhpz0YpV4o3E6hBuq0zAtFEbfag5JC6f6aiYiIahiGoBpm49FrGPvVXmhUCmyZ1B0R/nqX4wcTDmLY2mFQKVRY+/BahHkXnkSBiNws/Rpw+QBweT9wab/9MSuxcDu1t/16ooh2QHhb+2NAA85ER0REVEYMQTWMEAJDv9yJnWeT8HDbCMwb3KZQm1G/j8Lea3vxePPHMfm2ye4vkohKJgSQcj4vEF06YJ9wwZRRuK0+wB6I8g+l86vr9pKJiIg8CUNQDXT4Yiru/+hPAMCv/9cZrSIMLsd3XNqBpzY+Bb1Kj3UD1iFAFyBHmURUFjYrcOOUa2/R1cOA1VS4rW/d3FCUG47C2wJege6vmYiIqJpiCKqhnl15ED8euIQ7GgZh+RMdXW6gKoTA4F8H41jSMTx5y5MY33a8jJUSUblZTEDCv649RtePAcJWuG1Ag3zXF7WzD6vTeLu/ZiIiomqAIaiGupichZ7v/AGTxYaFI9ujZ7M6LsfXn1uP5/94Hr4aX2wYuAHeav4yRFQjmDLts9Fd2pfXa5QcV7idpLDfxDV/j1GdVrx/ERER1QoMQTXY7LXH8dkfZ9Ao1Ae/P9MFqnw3ULXarOj/U3+cSzuH5299HiNbjZSvUCKqWllJ+SZeyH1Mv1K4nVJjD0IR7YCwW4CgGCAwBvAN4+QLRERUozAE1WBpOWZ0e2sLkrPMePOhVnisY32X4z+e+hH/++t/CNYH4/cBv0Or5D1JiGqNtCuu1xdd2g/kpBTdVu0FBDa0L45g5Hj0CWVAIiIij8MQVMMt3hGHab8cRbCPBltf6AEfrcp5zGw1494f78XVzKt47fbX8EjTR2SslIhkJYR92Nyl/fZeo4RjQNIZIOVC0dcYOWh8gMAGrsHI8egdzIBERETVEkNQDWey2G+gGncjExN6NsJzdzd1Ob7s2DLM3j0bET4R+PWhX6FSqIo5ExHVShaTfbrupLNA4hl7MHI8psQDKOG/Ba1f8QHJK5ABiYiIZMMQVAv8fuQqnlq6Dzq1Alsn9UCYQec8lm3JRp/v+yDZmIzZXWajX8N+MlZKRB7FYgSSzxURkM4CqRdRYkDSGexhqNAQu4aczpuIiKqcx4SgadOmYfr06S77mjZtiuPHj5fq+bU5BAkh8Mjnf2PPuWQMujUScwe1djn+xT9f4MMDH6KRfyP88MAPUEiKYs5ERFRK5hz78LqiAlLapZKfqw9wDUWBMUBQQ8A/2n5MwX+jiIioYsqSDWQfJ9WyZUts3LjRua1SyV6SR5AkCS/f2xwPffIXvt9/EaM6NUCL8Lwv9pBmQ7DwyEKcTjmNb45/g8eaPyZjtURUI6h1QGhz+1KQKauIgHTW/ph+BchOBi7ttS8FSUr7tUbeIa6LT0jhfd4h9jqIiIgqQPbEoVKpEBYWJncZHqltvQDcd0td/PrPFcxaewxfj+noPOan8cOwFsPw2aHPMHv3bPx741+8cvsrvHcQEVUNjRdQp6V9KciUaQ9HRQWkjGuAsNofM66V7rW0frmhKTQvPPmE5oYkx/7cdX0Ar1MiIqJCZA9Bp06dQnh4OHQ6He644w7MmjUL9erVK7Kt0WiE0Wh0bqelpbmrzGprct9mWP/vNWw/dQN/nLyObk1CnMeeuuUpaBQafHzwY/xy9hccvnEYc7vNRbPAZjJWTES1jsYbCIu1LwVZTEBWIpCZAGReBzJvABn51gvut5kBY5p9STp789dWqIoOR87QlH8JBlS8rQARUW0g6zVBa9euRUZGBpo2bYorV65g+vTpuHTpEo4cOQJfX99C7Yu6hghArbwmKL83fzuKL7fHoWkdX6x5pguUCte/eu6/th8vbnsR17KuQaPQYFKHSRjSdAgk/nWUiDyJEEBOqms4ykjI3b6euy93PeM6YEwt+2voDPZFUgKSwt6LJCkKLPn2oajjjjbFHXM8r6TnFlhXqAGtr33RGXLX/XK3/XLX/ezrSnVlf/JERB7BYyZGKCglJQX169fHvHnzMGbMmELHi+oJioqKqvUhKDXLjK5ztyA124y3BtyCRzpEFWqTkpOC13a8hq0XtwIAetfrjWl3ToNBa3BztUREbmIx5gtMN/KFpiJ6mTKvAzaL3BVXDpUuLxC5hKV84cnlWIFtnR+g9uZkFUTkcTw2BAFAhw4d0Lt3b8yaNeumbWvz7HAFzd9+Fm/8dgyhvlpsfaE7vDSFRzoKIbDs2DK8s+8dWGwWhHuH461ub6F1SOsizkhEVIvYbEBOij0Q5aQCEPYbyrosoph1203aF3Us//OKO55vv9UEGDPsvVvGdCAnd0igcz0dMGdW4gciFdHT5Fs4LGlze850frkhyy9vW+PLIEVEbuVRs8Pll5GRgTNnzmDYsGFyl+Jxht1RH1/9fR4XkrLw5bY4PNO7caE2kiTh8RaPo21oW7yw7QXEp8dj5NqR+L92/4eRLUdyGm0iqr0UCvu9jDz5fkZWS14wcglIuUtOvmP5153buY/CCkDkBq5UoNyX30quoahgSCpyu0Co4jVaRFRFZO0JmjRpEu6//37Ur18fly9fxtSpU3Hw4EEcPXoUISEhN30+e4Jc/fbPFYxbvh9eGiW2vtAdob7FTyObYcrAjL9nYO25tQCATuGd8GbnNxGkD3JXuUREVN0IAZizC4Slgr1OjvXU3Dap9v35t62myqlHqXUNRTcLTlpfQKkBFEr7dVRKtX1yDMdS5LaaPVZENYTHDIcbMmQItm3bhsTERISEhKBz58548803ERMTU6rnMwS5EkLg4U//woELKRh6Wz3MeriImZgKtF91ahVm756NHGsOQvQhmN1lNm6re5ubKiYiohrJnFMgJKWWHJoKbhvdPfurlC8gqe0hyhmQlMUcKxisimursd/bSu0NqPWA2ss+pbxj3bEUtU9ZrQbsEFV7HhOCKoohqLC955Iw8LO/oZCA3yd2RZM6hWfZK+hU8im88McLOJN6BhIkPNn6STx5y5NQKfiPLxERycBmzdcbVVxoSinieLp9GnWbFbCa7ZNd2Mz2oYKOdWGT+92VnkKdG47yL/p8+/QFQlTBIKW3T1Gv1ucu3nn7dP4MWVTjMATVcv9dug9rj1xFj6YhWDSqdL062ZZszN49G6tOrQIA3FrnVszpMgd1vOtUZalERETuZbPlBiJLgcCUG5ryB6aC29bc9s5jRW1bXI9ZTYAlGzBl2YcamrNyl2z7jYSL2gc3/Wqm8we8guz3yPIKyluc247HQPs+jQ9vPkzVGkNQLRd3IxN3zfsDFpvAsrEd0alRcKmfu+bsGkz/ezqyLFnw1/rjzc5vomtk1yqsloiIiJyEsE/vnj8YmbNyQ1RF9mXbZxA0ZwOWnPLVptTmC0pBrkHJO1+Iyh+eeN8qciOGIMK0n//F4r/OoUVdP/z6f52hUJT+LzcX0i5g0h+TcCzpGABgeIvhmNhuItT8h4yIiMjzWS15U8JnJQJZuY+Zia7bzn03yh+cdIZ8QSk4dxbG4CJ6nYLY20QVxhBESMo0odvcLUjPsaBbkxAMv6M+ujcNhbKUYchkNWHevnlYdmwZAKBVUCu81e0tRPkWvhErERER1XCmzNxQdAPISsoXnPIFJmdwugFkJ6Ncw/qUWnsY8g62h6X8j0Wta30ZmsiJIYgAAN/svoApqw47t+sadBjcIQqDO0ShrkFfqnNsvrAZr+14DWmmNPiofTDtzmnoE92nqkomIiKimsBmtQchl6DkeEwqsC9325Jd9tdRakoOSQX3af0YmmowhiByOns9Ayv2xOO7vfFIzjIDABQS0LNZKB7tWA/dmty8d+hKxhW8uO1FHLx+EAAwqMkgvNjhRehUxd+HiIiIiKhMTJn2MJR5wx6OnI/X84bl5T9uzir7ayg1+YbhldTTFGJvpzMwNHkQhiAqxGix4vcjV/HN7gvYeTbJuT/coMPgDvUwuEMUwgzFhxqzzYxPDn6CBYcXQECgcUBjvN31bTT0b+iO8omIiIhcmbIKB6P8jwXXzZllfw2tAQiKAYIa5S4xeY/am9+GhNyLIYhKdOZ6BlbsvoDv910s0DtUB491rIeuTUKK7R366/JfmLJ9CpJykqBX6fFyx5fxYMyDkPhXEiIiIqrOzNklh6SCIcqUUfL5fMIKBKPcJSAaUGnc8pbIFUMQlUqO2Yp1/17F8l0XsCsur3cowl/vvHaojl/h3qEb2Tfw0vaXsOvKLgDAfQ3vw6u3vwpvtbfbaiciIiKqUqYsIOU8kHg633LG/ph5vfjnSQrAv37h3qPgxoBvOKBQuO891DIMQVRmpxMy8M3uC/hh/0Wk5PYOKRWS89qhro1de4esNisWHFmAjw9+DJuwob5ffbzd7W00C2wm11sgIiIico/sFCDpTF4oyh+SSupBUulzQ1GB3qOgRvbpw6lCGIKo3HLM9muHlu+6gN3nXHuHhnSIwiMFeof2X9uPF7e9iGtZ16BWqPFChxcwpOkQDo8jIiKi2kcIIP1q0b1HyXGAzVL8c/UBRVx71AgIbAhoONqmNBiCqFKcTkjH8l3x+GH/RaRm5/UO9crtHeqS2zuUkpOC13a8hq0XtwIAetXrhel3TodBa5CxeiIiIqJqxGrJHV5XRO9R2sWSn+sXkReMvIIBtc7eq6TSAmo9oNLlPmrt+4s7rtTU6NnuGIKoUuWYrVh75AqW77qAPeeSnfsj/PUYelsUHmkfhRBfLZYeW4p5++bBYrMg3Dscc7rOQZvQNvIVTkREROQJTFlA0tnCvUeJp4HspJs/v9Sk3EBUmhCly7dfl+95Re3TA/XvlD1gMQRRlTl1LR3Ld1/AD/suIi3H3qWrUkjo3bwOhnash8CAa5i8/UXEp8dDKSkxod0EjGw5EgqJFwESERERlVlWkmsoykkBzDmAJXcxZ+dbz7HfdLbgcVTxr/sKNfC/G1X7GqXAEERVLsdsxZrD9t6hvefzeociA/QY0D4YcViCLRfXAwA6hXfCm53fRJA+SK5yiYiIiGonIQCrOV84ygYsxrzwZM7dLvXxIsKXpASe/EPud8oQRO514mo6vtl9Aav25+8dAlo1O4ELWAazMCFYH4zZXWajY92OMldLRERERDURQxDJIttkxW+Hr+Cb3RewL7d3SKG9Ct96K2BTXYUECf+55T94qvVTUClUMldLRERERDUJQxDJ7vjVNKzYbZ9ZLt2YBW3Yz9D47wUAxPjGYuwtj6NpUGNE+0VDrVTLXC0REREReTqGIKo2sk1W/PrPZXyz+wL+SdkKXdgqSEqT87gEJYK04Wjs3wit6zRFo4BGaOTfCPX86kGtYDgiIiIiotJhCKJq6diVNMz/ezc2XP4WFuUlKLTXICmNRbZVQIlI33poFtgYjfwbIcY/Bo38GyHKL4rhiIiIiIgKYQiiak0IgQtJWThwIRm7LpzFwWvHcT49DjbVFSi0CVBorrn0FuWnklSINkSjkX8jNPRv6AxI9Xzr8TojIiIiolqMIYg8jsVqw6mEDPxzMQUH41Ow/1Ic4tLOQKivQam9BoX2GhTaBEiKosORWqG2hyNDXq9RjH8MIn0jGY6IiIiIagGGIKoRcsxWHL2ShkPxKfjnYioOXkzCueTLuYHIEY4S7MPqFOYiz6FRaBBtiHYJRo38GyHSJxJKhdLN74iIiIiIqgpDENVYqdlmHLmUikMXU/BPvP3xSmoWJHUKFNoEKDW5AUl3DUrtdQip6J4jrVKLBoYGaGjIG1JX368+InwioFPp3PyuiIiIiKiiGIKoVklIz3EGokMXU/HPxRSkZJkB2CCpk3N7jRKg0SdA730DZsVVWFF0OAKAEH0IIn0jEekTaX/Mtx6sD4ZCUrjvzRERERFRqTAEUa0mhEB8UjYOXkzBP7lD6Q5fSkW22ZrbIi8c+fjegL8hCZImAVm2a8i2ZpZ4bq1SiwifCGcwivKNcq5H+EZAr9JX/RskIiIiokIYgogKsFhtOH09A//Ep9rD0cUUHL+SDost/7e/gL+PBbc2sqFRuAkG3zQkZF/GxYyLuJh+EVczr8IqrMW+BgAE64OL7EGK9IlEiFcIe5GIiIiIqghDEFEp5JitOJY78cK+Cyn440QC0nIszuNqpYTbGwahd/M66NU8FHUMalzNvIqL6RedwSj/epoprcTX0yg0iPCNcAlG+cOSl9qrqt8yERERUY3FEERUDmarDXvPJWPTsWvYeOwaziVmuRxvFuaL3s3roHeLOrglwgCFQnI5nmpMxaWMS85gFJ8e7wxKVzKv3LQXKVAXWKj3KNI3EuE+4ajjVYdTfRMRERGVgCGIqIKEEDhzPdMZiPadT0b+kXMhvlr0bBqK3i3qoHOjYOg1JU+3bbFZ7L1IRfQgXcy4iFRjaonPV0pKhHmHIdwnHBE+Ec5HxxKiD+GU30RERFSrMQQRVbKkTBO2nkjAxmPXsO3kDWQY84bNaVUKdG4UjF6OYXN+ZZ9iO82Uhkvpl1xCUnx6PC5nXsbljMsw24q+D5KDSqFCXe+6CPcJR6RPpEtICvcJ56x2REREVOMxBBFVIZPFhl1xidh49Bo2HkvApZRsl+O3RBrQq5k9ELUM94MkScWcqXRswobrWddxOfMyLmVcwqX0S/b19Eu4lHEJVzOvwiIsJZ5Do9C49CIVDEuBusAK10lEREQkJ4YgIjcRQuDEtXRnIDp0MQX5f6LCDTr0bB6K3s3r4PaGQdCpK3/ImtVmRUJWAi5luIajSxmXcDnjMq5mXYVN2Eo8h06pcwlJBXuTDFoDQxIRERFVawxBRDJJSM/BluMJ2HgsAX+eupHv3kSAl0aJLo2D0bt5HfRsFoogH61bajLbzLiWeQ2XMy67hCPHekJWAgRK/mfAS+XlDEeB+kD4afzyFm3hdV+NLydyICIiIrdiCCKqBnLMVvx9JhEbjl3DpmPXcC3N6DwmSUDbKH/0blEHvZvXQeNQH9l6WsxWM65kXikyIF3OuIzr2dfLdV5vtXfRQamY4JR/nQGKiIiIyoohiKiaEULgyKU0bDx2DZuOX8ORS673FIoK1Nun325eB7c1CIRaWX0mMcix5OBK5hVnOErOSUaaKc2+GNPy1nO3syxZNz/pTXipvMoUnAK1gQjSB/FeS0RERLUYQxBRNXclNRubjiVg07Fr2HEmESZL3jU7vloVujUNQe/mddCkji+CfTQI8NZUq2BUErPNjHRTumtAKm69wHamObNCr+2l8kKQPgjB+mAE6YLy1vVBCNYFu2xrle4ZjkhERETuwRBE5EGyTBZsP3UDm45dw+bjCbiRYSqynZ9OhWAfLQK9NQjy0SDQW4tgHw0Cve2LyzEvDVQeEprys9gs9gBVhuCUakxFck4ycqw5ZXotX7UvgvR5QckRnBwhyRGcAvWBUCvUVfSOiYiIqLIwBBF5KJtN4ODFFGzKvR/RldRsJGWaXG7UWlr+Xmp7OPK2h6NAHw2CcwNTkI8WQbmPgd4aBHipPTI0OQghkGXJwo3sG0jMTsSN7Bv29ZxEJGYnOvcl5tgfb3bfpYL8tf6FA1IRwSlAG8Cb1hIREcmEIYioBrHZBFKyzUjKNOJGhglJmSYkZpqQmGG0r2eYkJhpRGLusaQsE8r6Uy1JgL9eXSAgFe5tCvLWwkujhEalgFqpgFopQa1UQKNUQKHwjCm0hRBIM6UVCkj5Q5Jjf1JO0k3vwZSfQlIgQBuAIH0QfDW+0Cl10Cq10Kq0znWdKndf7uLcLkUbnVIHlUJVLaYrF0LAIiwwW80wWU0w2Uww23LXrSZYbBaYbCbnttlmtrexml3aqRQqBOoD7cMXdUEI1AXCT+vHm/sSEVGZMQQR1WJWm0BKliMoOUKT0RmWkjJNeWEqw4iUbHOZQ1NRlArJJRSplQqoVQW2HceLCFFFtVe5HJegzn2ey/lUCjQK8UFUYOVPimATNqQaU4sMSAX3JeUk3XSq8cqgkBTOQKRV5QtK+bYd684QlhuyFFA4g4gjoJht5kLbRT0WDDBmm7nK3q9KUiFAZw+TjmAUpM97zL8vQBfA4YpERASAIYiIysBitSEl21yoRykxw1g4SGWakGO2wmwVsJZnjF4Vahbmi7ta1MFdLeogNsL9N3e12CxIMaY4A1KGOQNGqxE5lhwYrUaX9fz7jFYjcqw5MFpc13OsOTBZTc727ghYFaGQFNAoNFAr1VAr1NAoNfbt3HW1Uu2yrVFqoFKoYLFZnCEyMScR6ab0Mr+2QWsoHJZyJ8YouI8zCBIR1VwMQURU5aw2AbPVlrvY102WAttWG8yWAtuOxSJct60i3/Nzt602WPKtmy2ux8xWG7JNVpxKyHAJZWF+OvRuEYq7WoThjoZB0Kg8e2iVEAJmm9klIDlCU0khyhm0creFEM5AolbYQ4lGmS+oFHgsGGqK269RaCrtWiiT1eQMREnZuY85SfYeuAL7knOSYRXWm580H71KXygYOXuYcnuZDFqD87NxLrnbHKZHRFR9MQQRUa2SnGnClhMJ2HD0Gv44eR1ZprxfjH1ypxy/u0UddG8aCoOeQ6dqCsdwxfw9SfnXC4aoss4gWBSVpHIJRmqlPQhqldq87WICVMF1tUJtf16BgKlVap3ndWwrFUpYbBaYbWbXR6vZeW2WWRTeV+Rzch9LOlbSo2MdAAK0AQjUByJQ57oE6YKc+4N0QfBWe1eLa9mIqGZjCCKiWivHbMXfZxKx/ug1bDx2DdfTjc5jKoWEjg0DcVfzOrirZRgi/PUyVkruJIRAtiXb2aPkEpgKhKg0U5rLdVLVfSiiJ9AoNIXCkqMXrqj9aiX/WEFEZccQREQE+8x6hy6mYMPRa9hw9BpOJWS4HG9R1895HVHLcD/+pZoKccyC55jNLv8kEUarMW9CiYLbuRNIGK1Gl9nwXLbzzZ6X/7wmm72d47wmm322PbVCDZVCVeixqH0lHlOqoZLs28713EeX4/kfFSqXdbVCDSGE8zq4pJwk5+LofUvKtm9nWbLK/Ln7anzzQpJjKSZEcTbB6s1qsyLZmIzrWddxPfu68/FG9o28fdnXkZSdBK1SCz+tHwxaA/y1/jBoDK7bWgMMGoP9MXfx0/hBpVDJ/TapmmAIIiIqQtyNTGzMDUR7zye53H8pwl+P3s3t1xF1bBgItQffN4moOsm2ZCM5JzkvJDmu73IEp+wklxBV1uu8HLMJBuoC4a/1d04jr5AUUEDhXJcgFbnfccy5LkmlOu5cv8n5FJIC3mpveKu94av2hbcm91HtDV+NL/QqvUf+AcZsMyMxO9E11OQLOdezrjtn0bQJW5XW4qP2yQtGBUJS/m1/rb89VOWGq6qcWdImbMix5CDLkoVsc7b90ZKNbIvresFj2ZZsZJkLbBdor1FqXN5TwfdYcN1f6w9fjW+t+GMBQxAR0U0kZhix+bj9OqJtp64jx5z3n7SvToUeTUNxV4s66N40BL46Ds0hcgebsCHdlO68pit/OMo/dLEiswlWN46Q5KP2gY/Gx/7oWDR5j47QVFSY8tH4QKvUVko9RqvRtZcmq3DAuZF9A8k5yaUeKqqQFAjUBSJEH4JgfTBCvEIQorcvwV7BCNGHIEgfBJPVhFRjqn0xpTrXU4wpSDOmOfc5ttPNFfv6e6u97cFI4+calHK3/TR+EBBFB5OSgkruUp1IkOCn9bt5aNIYYNDZw6O/1t/jrudjCCIiKoMcsxV/nrqBDUevYdPxa7iRYXIeUysl3N4wCHe3qIPeLeqgroHXERFVF2ar2SUkpRhTYBM25yIg8taFgA351gsev0lbG/KtF9O+4HGrsMJqsyLLkoUMUwYyzBl5j+aMSu0hUSvURQenfL1O+XufUowprsEmyx500kxppX5NlaRCkD7IHmi8XEONYz1UH4oAXUCVDFmz2CxIN6XnBSNTmkuISslJQaop1R6gctukmlLdGp4lSNCpdPBSeUGv0kOv1kOv0udtq/TwUuetuxxT563nb2+0Gp3vN8WY4nyf+UNj/vXyDEl1UEmqvPCUr3etqB6nDmEdZO9tYggiIionq03gYHwy1ucOmzt7PdPleGyEwXkdUbMwX4/6CxkRVR+OyToyzZlIN6cj05T7aM4sFJgyzZlIN6UX2TbTnHnzFysjjUKT11vjldt7k9uLE+oV6uzN8df6y/5Lb3lYbVZ7eDK5BgZHqMgfpFSSqsiwkj+UFBlkcrd1Sp3s/0+YrWaXXjRHT5rjvboEqnzv32g13vzkuZSSEgeGHZD9vTIEERFVkjPXM5wTK+y/kIz8/2JGBerRu7k9EN0WHQgVryMiIjezCZszDDmDUu5jwZ4nx3qWOQsGrcF1aJqjJ0cfDD8NJ4ohIMeSU6hXqbgeJwGBr+75Su6SGYKIiKrC9XQjNh+3B6Ltp27AaMkbymLQq9Gzmf06oq5NQuCjLXrohxD2G72aLHk3iDVZbPn25a07Hx37La7H7DectTrPZSyirdlqgzF3n5dGiQbB3mgQ7IMGwV5oEOyDyAA9J4EgIqIagSGIiKiKZZks2J57HdHm4wlIysy7jkijVCAyQO8abJyhpHr9k6tSSIgK9MoNR96IDvZGw9z1MD8dFAr+NZiIiDwDQxARkRtZbQL7zidjw9Gr2HD0Gs4llv4iVJVCgkalgFqpgEalgCbfo1olObfVSgW0BdqpC7R3OY9KAY0y37mVCqRmm3EuMRNxNzJx9nomziVmusyKV5BOrUB0kHeRASnQW8PhMkREVK0wBBERyUQIgbM3MpGYYYI6N4TkDy8uYUepkLWnxWYTuJaeg7jrmTh7IxPnbtgDUtyNTFxIyoLFVvx/D746lTMQRec+Ngz2QXSwF6cUJyIiWTAEERFRhVisNlxMznaGovzL5dRslPQ/R7CPFg2DvRGde92RoyepfpAXdGql+94EERHVKgxBRERUZXLMVpxPzMoXjDJw7kYWzt7IxI2M4qdUlSQg3KB3hqIGwd6oa9BBr1FCr1ZCp1Y617VqBfRq+zpn3SMiotJgCCIiIlmk55hzA1GGMySdu2EfbpeeYynXOVUKyR6SnGFJ4QxNutygpNfY9zu3HccLPMcesPKe4zimUyuhVSl4nRMRkQcrSzao/Nv3EhFRreWrUyM20oDYSIPLfiEEEjNNzkAUdyMTcdftPUc5FiuyTVbkmG3INluRY7Yi22x1Drmz2ATSjRakG8sXokpLkgCdyh6K8k8ooXG5pkuCRqUsNOlEwUkq8rd3XBOmLmaSC8e1Y4VfK6+dkrP0ERFVKoYgIiKqcpIkIdhHi2AfLdpHB960vRD2+x4Zc4NRtjk3KFmsyDFZc8NS3rEcU154chzLyfec7HzHnWEr95hj2nIh4Hx+daNVKRDur0e4vw4R/npE+HvZ1wP0iPDXo65BD42KwwaJiEqLIYiIiKodSZKcw90MqNrZ5sxWmzMgGXPDU8Eb2ua/6WxRN7V13LjWeQPcAveIyv/8/Ocsuq39hrr5GS025/DCoj8vIMRHi4gAPcL99Yj019vXDXrnPoO+Zs/aZ7UJGC1W6NVKDmskoptiCCIiolrNMVStOk3tLYRwhiGzxYb0HAsupWTjckq2y+OllGxcSs6G0WJDQroRCelGHLiQUuQ5fbUqhDvCkb8OEf5euT1J9vUQX63sw+5sNoEMkwWpWWakZuctKQW2U7NNhY47rjnz0aoQ4eg1C8jrNYvMDYOhvjrZ3ycRyY8TIxAREXkwx/VWl3MD0aUCQelySg6SMk03PY9aKSHMoHP2HtmH3eX1JEX460s1xbkQApkmqz2gZBUfWhzradlmpORbL+H2VJVCpZBQ1z/vfUb66/OFw9K/TyKqfjg7HBERETllmSy5oSgHl5IL9yRdTcuBtRTpI8hb4xxmF+SjQYbR4gw1aflCTkk32i0NnVoBg14Ng14Nf70GfrnrBr0a/l5564b863o1dGolrqUVeI/5guHV1JxS1Rbso3EGooh8Icmx7e+l5pA7omqIIYiIiIhKzWK1D6dz9CBdLCJEZJnKNmGERqnIDS8q+HtpXMJKwSV/sPHLDTNVwWoTSEjPcQlGBQNTZinep5dGWWQ4cvQm1fHV8v5WRDJgCCIiIqJKI4RAarbZJTQkZZnhp1M5e2n8C/TMeOIEBUIIpGVbcDElq3CPWW4vWkk3BHZQKiSE+emc1yYZ9Gp4a1Xw0angm/voo1XDW6uEr1adu62Cr07F+1URVQBDEBEREVEVyDFbcSU1b8jdxQK9SVdSs53TrpeHUiHBR5sXiny0KtcA5QxRruu+utx2WhV8cwMWe6PyCGG/31hKphlJWSYkZ5mQnGlCcpY599GElCwzknLXk7Ps17H56dSIDNAjMsALkQF6RAV6ObfD/XXQqnj9WHXCEEREREQkA5tN4HqG0Tmk8GpqDtJzzEg3WpCRY0GGMd+Sk+/RZEFl/0amVyvhnS9M5Q9Neo0SenXuorFPR69XK+HlWHc5rnAe12uU0KmUUMg4w57NJpCWY0ZybmhJyTLlPtoDjmM7Ocucu25/rOi1agVJEhDqq0VUgJdLUIoM8EJUYM29f5fVJpCc+xknZtgfc8xWDLg1Uu7SGIKIiIiIPInNJpBltiLTaEF6/nBktE//nZkbnPKHKZe2ufvTjRaYLLabv2AFaVWKvKBUTKAqtK1RQJ97/y8vjcolXGlVSmSaLM5emfw9NI4Qk5TbW5OSZSr3LIJ6tRIBXmoEeGsQ4KWBv5cagd4a+HtpEJhvf0DudWyp2WZcTM5CfHIWLiZn5y5ZiE/KvumNlSUJCPPT5QWjAkGprr8O6mrQW2ey2JCclRdoEjONSMp0rJuQVGB/Sra5UGDXq5U49npfed5APmXJBrxPEBEREZHMFPmGwdWp4N91TRZbXmjKH5jyBatskw3ZZqv9RsEm+82Cs0xW542Ds/Ov524b84Uro8V+A+AUmCv4zsvPR6sqFGL8vTQI9NYgIN+6o02Al6Zck27ERhoK7RNCIDnLjPikLGcwcgak3Mccsw1XUnNwJTUHe84lFzqHwhGSAgv2JOkRFeCFugZduYY05pitzvBSVKBJzDQhKXd/YqbJeY+tsnJ8rkHe9s/ZYrV51BBM9gQRERER0U1ZbQJGS15oKviYF6AKByxnu3zbOS7PtcFHq4S/l8alp8YZYrw0hQJOdR5q5rh/V/6AVDAwGW/SY+eYYKNgQBJAXrDJcA00SZmmMs/kCNgDWWBumLEHG23euk/h/QFe6moZeDgcjoiIiIiomhJC4EaGKd8wO9fhdheTsys0rFGtlHKDi9bZU+PstfFx9N5onfsMerWs13lVFg6HIyIiIiKqpiRJQoivFiG+WrSrF1DouM0mcCPD6Bxalz8cKSQpL9gUEWgCfTTw1ao41fpNMAQREREREVUjCoWEUD8dQv10uLV+4ZBEFVf9BvMRERERERFVIYYgIiIiIiKqVRiCiIiIiIioVmEIIiIiIiKiWoUhiIiIiIiIahWGICIiIiIiqlUYgoiIiIiIqFZhCCIiIiIiolqFIYiIiIiIiGoVhiAiIiIiIqpVqk0Imj17NiRJwsSJE+UuhYiIiIiIarBqEYL27NmDzz//HLfccovcpRARERERUQ0newjKyMjAY489hi+//BIBAQFyl0NERERERDWc7CFo3Lhx6NevH3r37n3TtkajEWlpaS4LERERERFRWajkfPEVK1Zg//792LNnT6naz5o1C9OnT6/iqoiIiIiIqCaTrScoPj4ezzzzDJYtWwadTleq50yZMgWpqanOJT4+voqrJCIiIiKimkYSQgg5Xnj16tV46KGHoFQqnfusViskSYJCoYDRaHQ5VpS0tDQYDAakpqbCz8+vqksmIiIiIqJqqizZQLbhcL169cLhw4dd9o0aNQrNmjXD5MmTbxqAiIiIiIiIykO2EOTr64tWrVq57PP29kZQUFCh/cVxdGJxggQiIiIiotrNkQlKM9BN1okRKio9PR0AEBUVJXMlRERERERUHaSnp8NgMJTYRrZrgiqDzWbD5cuX4evrC0mS5C6nRktLS0NUVBTi4+N5/ZWb8DN3L37e7sfP3P34mbsfP3P34uftftXpMxdCID09HeHh4VAoSp7/zaN7ghQKBSIjI+Uuo1bx8/OT/Ru8tuFn7l78vN2Pn7n78TN3P37m7sXP2/2qy2d+sx4gB9lvlkpERERERORODEFERERERFSrMARRqWi1WkydOhVarVbuUmoNfubuxc/b/fiZux8/c/fjZ+5e/Lzdz1M/c4+eGIGIiIiIiKis2BNERERERES1CkMQERERERHVKgxBRERERERUqzAEERERERFRrcIQRJg1axY6dOgAX19fhIaGon///jhx4kSJz1m8eDEkSXJZdDqdmyr2fNOmTSv0+TVr1qzE53z33Xdo1qwZdDodYmNjsWbNGjdVWzNER0cX+swlScK4ceOKbM/v8bLZtm0b7r//foSHh0OSJKxevdrluBAC//vf/1C3bl3o9Xr07t0bp06duul5P/74Y0RHR0On06Fjx47YvXt3Fb0Dz1PSZ242mzF58mTExsbC29sb4eHhGD58OC5fvlziOcvzb1NtcrPv85EjRxb6/Pr27XvT8/L7vGg3+7yL+jddkiTMnTu32HPye7xkpfmdMCcnB+PGjUNQUBB8fHwwYMAAXLt2rcTzlvf/gP9v5/5joq7/OIA/zzxOIPmhxB1oEJgSUbCkpNNaC5iALsEoxDEHZREKTis3mouhs62fsy1Xl2uANRomTdSyZIDAikANUNGIqWOYg5O0QfwQYdzr+0fz9j3hjgPlDrjnY7vtPp/P+/Pm9Xnz2vvzed3nPjeZWAQRqqurkZmZibq6OpSVlWFoaAgrV65EX1+fxf3c3NzQ0dFhfLW1tdko4pkhJCTEZPx+/fVXs21/++03rF+/Hhs3bkRjYyMSEhKQkJCA8+fP2zDi6e306dMm411WVgYAePnll83uwxy3Xl9fH8LCwvD555+Puv2jjz7CZ599hi+//BInT56Eq6srYmJiMDAwYLbP7777Dm+99RZyc3PR0NCAsLAwxMTEoLOzc7IOY1qxNOb9/f1oaGhATk4OGhoacOjQIbS0tGDNmjVj9jueucnRjJXnABAbG2syfkVFRRb7ZJ6bN9Z4//84d3R0ID8/HwqFAomJiRb7ZY6bZ8014ZtvvokffvgBxcXFqK6uRnt7O1588UWL/U7kHDDphOgOnZ2dAkCqq6vNtikoKBB3d3fbBTXD5ObmSlhYmNXtk5KSZPXq1SbrIiIi5I033rjHkTmOrVu3yqJFi8RgMIy6nTk+cQCkpKTEuGwwGESj0cjHH39sXNfV1SUqlUqKiorM9rNs2TLJzMw0Lg8PD4uvr6+8//77kxL3dHbnmI/m1KlTAkDa2trMthnv3OTIRhvz1NRUiY+PH1c/zHPrWJPj8fHxEhkZabENc3x87rwm7OrqEqVSKcXFxcY2zc3NAkBqa2tH7WOi54DJxjtBNEJ3dzcAYN68eRbb9fb2wt/fHw8++CDi4+Nx4cIFW4Q3Y1y8eBG+vr4IDAxESkoKrly5YrZtbW0toqOjTdbFxMSgtrZ2ssOckQYHB1FYWIhXX30VCoXCbDvm+L3R2toKvV5vksPu7u6IiIgwm8ODg4Oor6832WfWrFmIjo5m3k9Qd3c3FAoFPDw8LLYbz9xEI1VVVcHb2xtBQUHYtGkTbty4YbYt8/zeuXbtGo4dO4aNGzeO2ZY5br07rwnr6+sxNDRkkrOPPPII/Pz8zObsRM4BtsAiiEwYDAZs27YNK1aswGOPPWa2XVBQEPLz83HkyBEUFhbCYDBg+fLluHr1qg2jnb4iIiKwf/9+HD9+HDqdDq2trXj22WfR09Mzanu9Xg+1Wm2yTq1WQ6/X2yLcGefw4cPo6upCWlqa2TbM8Xvndp6OJ4evX7+O4eFh5v09MjAwgOzsbKxfvx5ubm5m2413biJTsbGx+Oabb1BRUYEPP/wQ1dXViIuLw/Dw8Kjtmef3ztdff425c+eO+bUs5rj1Rrsm1Ov1cHJyGvFhiqWcncg5wBZm2+0v05SUmZmJ8+fPj/n9WK1WC61Wa1xevnw5goODsW/fPuzevXuyw5z24uLijO9DQ0MREREBf39/HDx40KpPseju5OXlIS4uDr6+vmbbMMdpphgaGkJSUhJEBDqdzmJbzk13Jzk52fj+8ccfR2hoKBYtWoSqqipERUXZMbKZLz8/HykpKWP+gA1z3HrWXhNOV7wTREZZWVn48ccfUVlZiYULF45rX6VSiSeeeAKXLl2apOhmNg8PDyxZssTs+Gk0mhG/vHLt2jVoNBpbhDejtLW1oby8HK+99tq49mOOT9ztPB1PDnt5eeG+++5j3t+l2wVQW1sbysrKLN4FGs1YcxNZFhgYCC8vL7Pjxzy/N3755Re0tLSMe14HmOPmmLsm1Gg0GBwcRFdXl0l7Szk7kXOALbAIIogIsrKyUFJSghMnTiAgIGDcfQwPD6OpqQk+Pj6TEOHM19vbi8uXL5sdP61Wi4qKCpN1ZWVlJncqyDoFBQXw9vbG6tWrx7Ufc3ziAgICoNFoTHL433//xcmTJ83msJOTE8LDw032MRgMqKioYN5b6XYBdPHiRZSXl2P+/Pnj7mOsuYksu3r1Km7cuGF2/Jjn90ZeXh7Cw8MRFhY27n2Z46bGuiYMDw+HUqk0ydmWlhZcuXLFbM5O5BxgE3b7SQaaMjZt2iTu7u5SVVUlHR0dxld/f7+xzYYNG+Sdd94xLu/atUtKS0vl8uXLUl9fL8nJyTJnzhy5cOGCPQ5h2nn77belqqpKWltbpaamRqKjo8XLy0s6OztFZOR419TUyOzZs+WTTz6R5uZmyc3NFaVSKU1NTfY6hGlpeHhY/Pz8JDs7e8Q25vjd6enpkcbGRmlsbBQAsmfPHmlsbDT+EtkHH3wgHh4ecuTIETl37pzEx8dLQECA3Lx509hHZGSk7N2717h84MABUalUsn//fvnjjz8kPT1dPDw8RK/X2/z4piJLYz44OChr1qyRhQsXypkzZ0zm9lu3bhn7uHPMx5qbHJ2lMe/p6ZHt27dLbW2ttLa2Snl5uSxdulQWL14sAwMDxj6Y59Yba14REenu7hYXFxfR6XSj9sEcHx9rrgkzMjLEz89PTpw4Ib///rtotVrRarUm/QQFBcmhQ4eMy9acA2yNRRAJgFFfBQUFxjbPPfecpKamGpe3bdsmfn5+4uTkJGq1WlatWiUNDQ22D36aWrdunfj4+IiTk5MsWLBA1q1bJ5cuXTJuv3O8RUQOHjwoS5YsEScnJwkJCZFjx47ZOOrpr7S0VABIS0vLiG3M8btTWVk56jxye0wNBoPk5OSIWq0WlUolUVFRI/4P/v7+kpuba7Ju7969xv/DsmXLpK6uzkZHNPVZGvPW1lazc3tlZaWxjzvHfKy5ydFZGvP+/n5ZuXKlPPDAA6JUKsXf319ef/31EcUM89x6Y80rIiL79u0TZ2dn6erqGrUP5vj4WHNNePPmTdm8ebN4enqKi4uLrF27Vjo6Okb08//7WHMOsDWFiMjk3GMiIiIiIiKaevhMEBERERERORQWQURERERE5FBYBBERERERkUNhEURERERERA6FRRARERERETkUFkFERERERORQWAQREREREZFDYRFEREREREQOhUUQERE5LIVCgcOHD9s7DCIisjEWQUREZBdpaWlQKBQjXrGxsfYOjYiIZrjZ9g6AiIgcV2xsLAoKCkzWqVQqO0VDRESOgneCiIjIblQqFTQajcnL09MTwH9fVdPpdIiLi4OzszMCAwPx/fffm+zf1NSEyMhIODs7Y/78+UhPT0dvb69Jm/z8fISEhEClUsHHxwdZWVkm269fv461a9fCxcUFixcvxtGjRyf3oImIyO5YBBER0ZSVk5ODxMREnD17FikpKUhOTkZzczMAoK+vDzExMfD09MTp06dRXFyM8vJykyJHp9MhMzMT6enpaGpqwtGjR/Hwww+b/I1du3YhKSkJ586dw6pVq5CSkoJ//vnHpsdJRES2pRARsXcQRETkeNLS0lBYWIg5c+aYrN+xYwd27NgBhUKBjIwM6HQ647ann34aS5cuxRdffIGvvvoK2dnZ+Ouvv+Dq6goA+Omnn/DCCy+gvb0darUaCxYswCuvvIL33ntv1BgUCgXeffdd7N69G8B/hdX999+Pn3/+mc8mERHNYHwmiIiI7Ob55583KXIAYN68ecb3Wq3WZJtWq8WZM2cAAM3NzQgLCzMWQACwYsUKGAwGtLS0QKFQoL29HVFRURZjCA0NNb53dXWFm5sbOjs7J3pIREQ0DbAIIiIiu3F1dR3x9bR7xdnZ2ap2SqXSZFmhUMBgMExGSERENEXwmSAiIpqy6urqRiwHBwcDAIKDg3H27Fn09fUZt9fU1GDWrFkICgrC3Llz8dBDD6GiosKmMRMR0dTHO0FERGQ3t27dgl6vN1k3e/ZseHl5AQCKi4vx5JNP4plnnsG3336LU6dOIS8vDwCQkpKC3NxcpKamYufOnfj777+xZcsWbNiwAWq1GgCwc+dOZGRkwNvbG3Fxcejp6UFNTQ22bNli2wMlIqIphUUQERHZzfHjx+Hj42OyLigoCH/++SeA/3657cCBA9i8eTN8fHxQVFSERx99FADg4uKC0tJSbN26FU899RRcXFyQmJiIPXv2GPtKTU3FwMAAPv30U2zfvh1eXl546aWXbHeAREQ0JfHX4YiIaEpSKBQoKSlBQkKCvUMhIqIZhs8EERERERGRQ2ERREREREREDoXPBBER0ZTEb2sTEdFk4Z0gIiIiIiJyKCyCiIiIiIjIobAIIiIiIiIih8IiiIiIiIiIHAqLICIiIiIicigsgoiIiIiIyKGwCCIiIiIiIofCIoiIiIiIiBzK/wCGvDjwHh1EXQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Obtener la longitud máxima entre los tres history_ppl\n",
        "max_epochs = max(len(history_ppl), len(history_ppl_lstm), len(history_ppl_GRU))\n",
        "\n",
        "# Rellenar con NaN para igualar las longitudes\n",
        "history_ppl_vector = np.pad(history_ppl, (0, max_epochs - len(history_ppl)), 'constant', constant_values=np.nan)\n",
        "history_ppl_lstm_vector = np.pad(history_ppl_lstm, (0, max_epochs - len(history_ppl_lstm)), 'constant', constant_values=np.nan)\n",
        "history_ppl_gru_vector = np.pad(history_ppl_GRU, (0, max_epochs - len(history_ppl_GRU)), 'constant', constant_values=np.nan)\n",
        "\n",
        "epoch_count = range(1, max_epochs + 1)\n",
        "\n",
        "# Graficar con todas las épocas, usando NaN para los valores faltantes\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x=epoch_count, y=history_ppl_vector, label=\"SimpleRNN\")\n",
        "sns.lineplot(x=epoch_count, y=history_ppl_lstm_vector, label=\"LSTM\")\n",
        "sns.lineplot(x=epoch_count, y=history_ppl_gru_vector, label=\"GRU\")\n",
        "\n",
        "# Etiquetas y título\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.title('Evolution of Perplexity - Comparison of Models')\n",
        "\n",
        "# Mostrar leyenda\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bYZOJFEEATr"
      },
      "source": [
        "El gráfico muestra que el modelo SimpleRNN alcanzó la menor perplejidad al final del entrenamiento, superando a LSTM y GRU en este aspecto. Sin embargo, es importante notar las diferencias en las trayectorias de aprendizaje de los tres modelos.\n",
        "\n",
        "- LSTM comenzó con la perplejidad más alta pero mostró la mejora más dramática en las primeras épocas, lo que sugiere un potencial significativo para el aprendizaje. Aunque terminó con la perplejidad más alta entre los tres modelos, su curva de aprendizaje indica que podría beneficiarse de un entrenamiento más prolongado o de un ajuste de hiperparámetros.\n",
        "\n",
        "- GRU mostró un rendimiento intermedio, acercándose mucho al SimpleRNN en las últimas épocas. Su curva de aprendizaje más suave sugiere una mayor estabilidad durante el entrenamiento, lo que podría ser una ventaja en ciertos escenarios.\n",
        "\n",
        "- Tanto LSTM como GRU se implementaron con menos unidades recurrentes (100) en comparación con SimpleRNN (200), dado el coste computacional que representaba. Esto implica que el potencial completo de LSTM y GRU podría no haberse alcanzado\n",
        "\n",
        "- En cuanto a la eficiencia computacional, SimpleRNN demostró ser el más rápido en entrenamiento, lo cual es esperado dada su arquitectura más simple. LSTM y GRU, siendo modelos más complejos, requirieron más tiempo de entrenamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN6Fg_BsxJe6"
      },
      "source": [
        "\n",
        "### Predicción del próximo caracter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "DA25KF6uGK8d"
      },
      "outputs": [],
      "source": [
        "# Procedo a cargar todos los modelos guardados\n",
        "# Esto puede variar entre drive y el github local\n",
        "\n",
        "model_simpleRNN = keras.models.load_model('drive/MyDrive/Colab Notebooks/desafio_3/model_simpleRNN.keras')\n",
        "model_LSTM = keras.models.load_model('drive/MyDrive/Colab Notebooks/desafio_3/model_lstm.keras')\n",
        "model_GRU = keras.models.load_model('drive/MyDrive/Colab Notebooks/desafio_3/model_gru.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBvKHFPmzpy2",
        "outputId": "1e6b2507-effd-490a-ad25-4bdb268fb051"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Se puede usar gradio para probar el modelo\n",
        "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
        "# https://gradio.app/\n",
        "\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "HNyBykvhzs7-",
        "outputId": "9037fcf7-3f65-4755-bdd4-d3a0fc833baa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://a15bd48b7439d0b4c7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a15bd48b7439d0b4c7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://a15bd48b7439d0b4c7.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def model_response(human_text, model=model_simpleRNN):\n",
        "\n",
        "    # Encodeamos\n",
        "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
        "    # Si tienen distinto largo\n",
        "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
        "\n",
        "    # Predicción softmax\n",
        "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
        "\n",
        "\n",
        "    # Debemos buscar en el vocabulario el caracter\n",
        "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
        "    out_word = ''\n",
        "    out_word = idx2char[y_hat]\n",
        "\n",
        "    # Agrego la palabra a la frase predicha\n",
        "    return human_text + out_word\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=model_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\")\n",
        "\n",
        "iface.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeCSnXnMIQxh"
      },
      "source": [
        "A continuación voy a poner una ejecución por medio de la salida de la funcion \"model response\" de forma de dejar acentado el valor de la predicción.\n",
        "\n",
        "Para ello dejo 3 casos donde:\n",
        "\n",
        "1. Probamos \"albu\" en referencia a Albus Dumbledore, y vemos que podria no ser trivial la respuesta siendo por ejemplo \"album\"\n",
        "2. Una frase que finaliza en \"qui\" siendo que se busca la palabra \"quidditch\" en referencia al popular deporte\n",
        "3. La misma frase que el item anterior, pero siendo \"quid\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhri129ZIfj6",
        "outputId": "7e0c6f1c-c4b9-4950-8932-184faca20886"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Modelo SimpleRNN: albut\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Modelo LSTM: albus\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Modelo GRU: albus\n"
          ]
        }
      ],
      "source": [
        "# Prueba del modelo:\n",
        "\n",
        "test_string = \"albu\"\n",
        "print(f'Modelo SimpleRNN: { model_response(test_string, model_LSTM) }')\n",
        "print(f'Modelo LSTM: {model_response(test_string, model_simpleRNN)}')\n",
        "print(f'Modelo GRU: {model_response(test_string, model_GRU)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSsKb-HYKw_c",
        "outputId": "4ad5b67b-dec3-4003-ea28-03e136a38528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PALABRA CON MAS CONTEXTO\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Modelo SimpleRNN: Harry's broomstick was the best in the quir\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Modelo LSTM: Harry's broomstick was the best in the quid\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
            "Modelo GRU: Harry's broomstick was the best in the quid\n"
          ]
        }
      ],
      "source": [
        "test_string_2 = \"Harry's broomstick was the best in the qui\"\n",
        "print(\"PALABRA CON MAS CONTEXTO\")\n",
        "print(f'Modelo SimpleRNN: { model_response(test_string_2, model_LSTM) }')\n",
        "print(f'Modelo LSTM: {model_response(test_string_2, model_simpleRNN)}')\n",
        "print(f'Modelo GRU: {model_response(test_string_2, model_GRU)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KnMQKV8LVK1",
        "outputId": "b084abc5-cf46-44e8-9d1a-88e141013eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PALABRA CON MAS CONTEXTO\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Modelo SimpleRNN: Harry's broomstick was the best in the quidd\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Modelo LSTM: Harry's broomstick was the best in the quidd\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Modelo GRU: Harry's broomstick was the best in the quidd\n"
          ]
        }
      ],
      "source": [
        "test_string_2 = \"Harry's broomstick was the best in the quid\"\n",
        "print(\"PALABRA CON MAS CONTEXTO\")\n",
        "print(f'Modelo SimpleRNN: { model_response(test_string_2, model_LSTM) }')\n",
        "print(f'Modelo LSTM: {model_response(test_string_2, model_simpleRNN)}')\n",
        "print(f'Modelo GRU: {model_response(test_string_2, model_GRU)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0V9u3Q-MGbB"
      },
      "source": [
        "En esta prueba evaluamos los 3 modelos (SimpleRNN, LSTM y GRU) utilizando diferentes frases incompletas para observar cómo completan las palabras según el contexto.\n",
        "\n",
        "Prueba con \"albu\"\n",
        "\n",
        "- El Modelo SimpleRNN completó incorrectamente la palabra como \"albut\", lo cual es una predicción fallida.\n",
        "- Tanto el Modelo LSTM como el Modelo GRU lograron completar correctamente la palabra como \"albus\", lo que refleja una mejor capacidad para capturar el contexto en esta prueba.\n",
        "\n",
        "Pruebas con **Harry's broomstick was the best in the qui**:\n",
        "\n",
        "- El Modelo SimpleRNN generó \"quir\", lo cual es incorrecto al contexto aplicado y los demas logrron completar correctamente con \"quid\" que era esperado\n",
        "\n",
        "Prueba con **Harry's broomstick was the best in the quid**:\n",
        "\n",
        "- Todos los modelos (SimpleRNN, LSTM, GRU) predijeron correctamente la continuación \"quidd\"\n",
        "\n",
        "\n",
        "El SimpleRNN mostró dificultades para completar correctamente las palabras en las pruebas, lo cual es coherente con sus limitaciones para capturar dependencias a largo plazo.\n",
        "Tanto el LSTM como el GRU completaron de manera más precisa en ambas pruebas, mostrando su capacidad para manejar mejor el contexto en la generación de texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCeMWWupxN1-"
      },
      "source": [
        "### Generación de secuencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "bwbS_pfhxvB3"
      },
      "outputs": [],
      "source": [
        "def generate_seq(model, seed_text, max_length, n_words):\n",
        "    \"\"\"\n",
        "        Exec model sequence prediction\n",
        "\n",
        "        Args:\n",
        "            model (keras): modelo entrenado\n",
        "            seed_text (string): texto de entrada (input_seq)\n",
        "            max_length (int): máxima longitud de la sequencia de entrada\n",
        "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
        "        returns:\n",
        "            output_text (string): sentencia con las \"n_words\" agregadas\n",
        "    \"\"\"\n",
        "    output_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "    for _ in range(n_words):\n",
        "\t\t# Encodeamos\n",
        "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
        "\t\t# Si tienen distinto largo\n",
        "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "\t\t# Predicción softmax\n",
        "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
        "\t\t# Vamos concatenando las predicciones\n",
        "        out_word = ''\n",
        "\n",
        "        out_word = idx2char[y_hat]\n",
        "\n",
        "\t\t# Agrego las palabras a la frase predicha\n",
        "        output_text += out_word\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoFqRC5pxzqS",
        "outputId": "96664bc4-690f-4209-bdb0-fa69fae26ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERACIÓN DE SECUENCIAS\n",
            "Modelo SimpleRNN:\n",
            "Harry, Ron and Hermione were in the dursleys were the stone -\n",
            "Modelo LSTM:\n",
            "Harry, Ron and Hermione were in the started the starts and th\n",
            "Modelo GRU:\n",
            "Harry, Ron and Hermione were in the stone of the stone of the\n"
          ]
        }
      ],
      "source": [
        "input_text='Harry, Ron and Hermione were in'\n",
        "\n",
        "print(\"GENERACIÓN DE SECUENCIAS\")\n",
        "print('Modelo SimpleRNN:')\n",
        "print(generate_seq(model_simpleRNN, input_text, max_length=max_context_size, n_words=30))\n",
        "\n",
        "print('Modelo LSTM:')\n",
        "print(generate_seq(model_LSTM, input_text, max_length=max_context_size, n_words=30))\n",
        "\n",
        "print('Modelo GRU:')\n",
        "print(generate_seq(model_GRU, input_text, max_length=max_context_size, n_words=30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMdK8bovOy4b"
      },
      "source": [
        "En las pruebas de generación de secuencias con el texto inicial \"Harry, Ron and Hermione were in\":\n",
        "\n",
        "- Modelo SimpleRNN: Produjo una salida confusa y menos coherente: \"the dursleys were the stone -\".\n",
        "- Modelo LSTM: Generó una secuencia más coherente que el SimpleRNN, pero con fragmentos poco lógicos: \"the started the starts and th\".\n",
        "- Modelo GRU: tiene la salida más relevante y fluida: \"the stone of the stone of the\", mostrando una mejor comprensión del contexto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJ6xn5qW1Hl"
      },
      "source": [
        "###  Beam search y muestreo aleatorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_vovn9XZW1Hl"
      },
      "outputs": [],
      "source": [
        "# funcionalidades para hacer encoding y decoding\n",
        "\n",
        "def encode(text,max_length=max_context_size):\n",
        "\n",
        "    encoded = [char2idx[ch] for ch in text]\n",
        "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def decode(seq):\n",
        "    return ''.join([idx2char[ch] for ch in seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "I_lZiQwkW1Hl"
      },
      "outputs": [],
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# función que selecciona candidatos para el beam search\n",
        "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
        "\n",
        "  # colectar todas las probabilidades para la siguiente búsqueda\n",
        "  pred_large = []\n",
        "\n",
        "  for idx,pp in enumerate(pred):\n",
        "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
        "\n",
        "  pred_large = np.array(pred_large)\n",
        "\n",
        "  # criterio de selección\n",
        "  if mode == 'det':\n",
        "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
        "  elif mode == 'sto':\n",
        "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
        "  else:\n",
        "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
        "\n",
        "  # traducir a índices de token en el vocabulario\n",
        "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
        "                        np.array([idx_select%vocab_size]).T),\n",
        "                      axis=1)\n",
        "\n",
        "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
        "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
        "\n",
        "\n",
        "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
        "\n",
        "    # first iteration\n",
        "\n",
        "    # encode\n",
        "    encoded = encode(input)\n",
        "\n",
        "    # first prediction\n",
        "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
        "\n",
        "    # get vocabulary size\n",
        "    vocab_size = y_hat.shape[0]\n",
        "\n",
        "    # initialize history\n",
        "    history_probs = [0]*num_beams\n",
        "    history_tokens = [encoded[0]]*num_beams\n",
        "\n",
        "    # select num_beams candidates\n",
        "    history_probs, history_tokens = select_candidates([y_hat],\n",
        "                                        num_beams,\n",
        "                                        vocab_size,\n",
        "                                        history_probs,\n",
        "                                        history_tokens,\n",
        "                                        temp,\n",
        "                                        mode)\n",
        "\n",
        "    # beam search loop\n",
        "    for i in range(num_words-1):\n",
        "\n",
        "      preds = []\n",
        "\n",
        "      for hist in history_tokens:\n",
        "\n",
        "        # actualizar secuencia de tokens\n",
        "        input_update = np.array([hist[i+1:]]).copy()\n",
        "\n",
        "        # predicción\n",
        "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
        "\n",
        "        preds.append(y_hat)\n",
        "\n",
        "      history_probs, history_tokens = select_candidates(preds,\n",
        "                                                        num_beams,\n",
        "                                                        vocab_size,\n",
        "                                                        history_probs,\n",
        "                                                        history_tokens,\n",
        "                                                        temp,\n",
        "                                                        mode)\n",
        "\n",
        "    return history_tokens[:,-(len(input)+num_words):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FiG6SnbPJ4u",
        "outputId": "a6f3b235-a1e0-44f5-8bcd-3a7b19fce0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo SimpleRNN: harry, ron and hermione were in the dursleys of the\n",
            "Modelo LSTM: harry, ron and hermione were in the couldn’t harry \n",
            "Modelo GRU: harry, ron and hermione were in the dursleys of the\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search en modo determinista\n",
        "string_to_search = \"harry, ron and hermione were in\"\n",
        "print(f\"Modelo SimpleRNN: {decode(beam_search(model_simpleRNN,num_beams=10,num_words=20,input=string_to_search,temp=1,mode='det')[0])}\")\n",
        "print(f'Modelo LSTM: {decode(beam_search(model_LSTM,num_beams=10,num_words=20,input=string_to_search,temp=1,mode=\"det\")[0])}')\n",
        "print(f'Modelo GRU: {decode(beam_search(model_GRU,num_beams=10,num_words=20,input=string_to_search,temp=1,mode=\"det\")[0])}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuMRkbfmSjpW",
        "outputId": "349b804b-7c41-440c-abd9-8da04a68b712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo SimpleRNN, temp=5: harry, ron and hermione were in feet you segie cra’\n",
            "Modelo LSTM, temp=5: harry, ron and hermione were ingrawl — shocring oti\n",
            "Modelo GRU, temp=5: harry, ron and hermione were intrid whas mugh wavch\n"
          ]
        }
      ],
      "source": [
        "# predicción con beam search en modo est\n",
        "string_to_search = \"harry, ron and hermione were in\"\n",
        "print(f\"Modelo SimpleRNN, temp=5: {decode(beam_search(model_simpleRNN,num_beams=10,num_words=20,input=string_to_search,temp=5,mode='sto')[0])}\")\n",
        "print(f'Modelo LSTM, temp=5: {decode(beam_search(model_LSTM,num_beams=10,num_words=20,input=string_to_search,temp=5,mode=\"sto\")[0])}')\n",
        "print(f'Modelo GRU, temp=5: {decode(beam_search(model_GRU,num_beams=10,num_words=20,input=string_to_search,temp=5,mode=\"sto\")[0])}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCOKF5lNToCP"
      },
      "source": [
        "Podemos ver como para el modo determinsta, las salidas son coherentes y similares en cuanto a la generacion de texto y espacios de las oraciones.\n",
        "\n",
        "En el modelo con modo estocastico, una temperatura mayo comenzo a generar freses poco legibles o realistas perdiendo el sentido y coherencia.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e39PtuG8Uksa"
      },
      "source": [
        "### Conclusiones generales:\n",
        "\n",
        "En este notebook se entrenaron modelos de lenguaje basados en redes neuronales recurrentes utilizando el texto del primer libro de Harry Potter en inglés.\n",
        "\n",
        "Los resultados indicaron que, aunque SimpleRNN presentó una perplejidad competitiva, tanto LSTM como GRU mostraron potencial de mejora en sus curvas de aprendizaje, sugiriendo que un ajuste más cuidadoso de los hiperparámetros o un mayor número de épocas podría beneficiar su rendimiento.\n",
        "\n",
        "Las pruebas de predicción con Beam Search mostraron que las arquitecturas fueron capaces de reconocer patrones y generar texto relevante, aunque se evidenció que en el modo estocástico, especialmente con temperaturas elevadas, la generación de texto presentó incoherencias notables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_LlqmtEW1Hn"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
